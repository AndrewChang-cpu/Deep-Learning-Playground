{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.transforms import ToTensorfrom \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "669251ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753876, 5)\n",
      "(205861, 5)\n",
      "(205861, 5)\n"
     ]
    }
   ],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, pts_file, split=0):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "        # points = np.delete(points, -2, 1)\n",
    "\n",
    "        if split == 1:\n",
    "            points = points[:len(points)//2]\n",
    "        elif split == 2:\n",
    "            points = points[len(points)//2:]\n",
    "\n",
    "        print(points.shape)\n",
    "        # do i need to min max intensity, return number, number of returns, etc.? probably not\n",
    "        for i in range(4):\n",
    "            dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "            points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "        self.data = points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 25000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 2500 points\n",
    "        xyzirn = self.data[idx * 25000: (idx + 1) * 25000, :-1]  # x, y, z, ***intensity, return number, number of returns***\n",
    "        label = self.data[idx * 25000: (idx + 1) * 25000, -1] == 5\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float() # intensity, z, y, x from top to bottom\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return xyzirn, label\n",
    "\n",
    "training_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_Traininig.pts\")\n",
    "validation_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\", split=1)\n",
    "testing_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\", split=2)\n",
    "train_dataloader = DataLoader(training_data, batch_size=10, shuffle=True) # can/should i use shuffle, try lowering it?\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=10, shuffle=False)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=10, shuffle=False)\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 25000])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader))[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97740441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 25000])\n",
      "torch.Size([10, 25000])\n",
      "torch.Size([10, 25000])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    print(data[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2f1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 4, 25000])\n",
      "Labels batch shape: torch.Size([10, 25000])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d56a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 597983, 1: 152017}) 750000\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def plot_batch(entire_view = True):\n",
    "    # Assuming pc is your point cloud data, in shape (N, 3)\n",
    "    pc_num = 0\n",
    "\n",
    "    if entire_view:\n",
    "        pc = training_data.data[:, :3]\n",
    "        labels = training_data.data[:, 3] == 8\n",
    "    else:\n",
    "        pc = training_data[pc_num][0].T.view(-1,3).numpy()\n",
    "        labels = training_data[pc_num][1].numpy()\n",
    "\n",
    "    print(Counter(labels), len(labels))\n",
    "\n",
    "    # Define colors for each label\n",
    "    color_map = {0: [0.5, 0.5, 0.5],  # Gray color for label 0\n",
    "                1: [1.0, 0.0, 0.0]}  # Red color for label 1\n",
    "\n",
    "    # Map each label to a color\n",
    "    colors = np.array([color_map[label] for label in labels])\n",
    "\n",
    "    # Create point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pc)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "# plot_batch(entire_view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4086ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.mlp1 = nn.Sequential(torch.nn.Conv1d(k, 64, 1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(torch.nn.Conv1d(64, 128, 1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp3 = nn.Sequential(torch.nn.Conv1d(128, 1024, 1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Linear(512, 256), nn.BatchNorm1d(256), nn.GELU())\n",
    "        self.fc = nn.Linear(256, k*k)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.mlp3(x)\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = self.mlp4(x)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        iden = torch.eye(self.k, requires_grad=True).repeat(batchsize,1,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x.view(-1, self.k, self.k) + iden\n",
    "\n",
    "        return x\n",
    "    \n",
    "class PoinNet(nn.Module):\n",
    "    def __init__(self, input_dim=6, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Should GELU be after LayerNorm?\n",
    "        self.stn1 = STNkd(k=input_dim)\n",
    "        self.mlp1 = nn.Sequential(nn.Conv1d(input_dim, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        \n",
    "        self.stn2 = STNkd(k=64)\n",
    "        self.mlp3 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        \n",
    "        self.mlp6 = nn.Sequential(nn.Linear(1088, 512), nn.LayerNorm(512), nn.GELU())\n",
    "        self.mlp7 = nn.Sequential(nn.Linear(512, 256), nn.LayerNorm(256), nn.GELU())\n",
    "        self.mlp8 = nn.Sequential(nn.Linear(256, 128), nn.LayerNorm(128), nn.GELU())\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.debug = nn.Conv1d(input_dim, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "\n",
    "        trans6x6 = self.stn1(x) \n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans6x6)\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "        # print(1, x.size())\n",
    "        x = self.mlp2(x)\n",
    "        # print(2, x.size())\n",
    "        \n",
    "        \n",
    "        trans64x64 = self.stn2(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans64x64)\n",
    "        local_features = x.transpose(2, 1)\n",
    "        \n",
    "        x = self.mlp3(local_features)\n",
    "        # print(3, x.size())\n",
    "        x = self.mlp4(x)\n",
    "        # print(4, x.size())\n",
    "        x = self.mlp5(x)\n",
    "        # print(5, x.size())\n",
    "        x = torch.max(x, 2)[0]\n",
    "        # print(6, x.size())\n",
    "        \n",
    "        # FOR CLASSIFICATION\n",
    "        # x = self.mlp6(x)\n",
    "        # print(6, x.size())\n",
    "        # x = self.mlp7(x)\n",
    "        # print(7, x.size())\n",
    "        # x = self.fc(x)\n",
    "        # print(8, x.size())\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "\n",
    "        global_features = x.unsqueeze(2).repeat(1, 1, n_pts)\n",
    "        # print(7, global_features.size())\n",
    "        x = torch.cat([local_features, global_features], 1)\n",
    "        # print(8, x.size())\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.mlp6(x)\n",
    "        # print(9, x.size())\n",
    "        x = self.mlp7(x)\n",
    "        # print(10, x.size())\n",
    "        x = self.mlp8(x)\n",
    "        # print(11, x.size())\n",
    "        x = self.fc(x)\n",
    "        print(12, x.size())\n",
    "\n",
    "        # x = x.view(-1, 2)\n",
    "        # print(x, x.size())\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        # print(x, x.size())\n",
    "\n",
    "        return x, trans64x64\n",
    "        # return x, trans64x64\n",
    "\n",
    "# model = PoinNet(input_dim=6, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size(1)\n",
    "    I = torch.eye(d).unsqueeze(0).to(device)\n",
    "    loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e075a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, trans):\n",
    "        d = trans.size(1)\n",
    "        I = torch.eye(d).unsqueeze(0).to(device)\n",
    "        loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "        loss = torch.mean(loss)\n",
    "        return self.cross_entropy_loss(inputs, targets) + loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cad6a3",
   "metadata": {},
   "source": [
    "## Online Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "294c68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[0] train loss: 0.7099375327428182 accuracy: 0.6192346666666667 f1 score: 0.2556547758680909\n",
      "[0] validation loss: 0.44683578610420227 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[1] train loss: 0.589138905207316 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[1] validation loss: 0.419990599155426 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[2] train loss: 0.5702248215675354 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[2] validation loss: 0.4211133122444153 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[3] train loss: 0.5531713366508484 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[3] validation loss: 0.4492341876029968 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[4] train loss: 0.5459369619687399 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[4] validation loss: 0.4435502588748932 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[5] train loss: 0.5286495983600616 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[5] validation loss: 0.4222731590270996 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[6] train loss: 0.5133774081865946 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[6] validation loss: 0.4309663772583008 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[7] train loss: 0.5105622708797455 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[7] validation loss: 0.4326340854167938 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[8] train loss: 0.506435344616572 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[8] validation loss: 0.4381144642829895 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[9] train loss: 0.49540094534556073 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[9] validation loss: 0.4400370717048645 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[10] train loss: 0.4882759153842926 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[10] validation loss: 0.43940240144729614 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[11] train loss: 0.4746323029200236 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[11] validation loss: 0.4228472411632538 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[12] train loss: 0.4779207507769267 accuracy: 0.818336 f1 score: 0.05135631927811508\n",
      "[12] validation loss: 0.42183926701545715 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[13] train loss: 0.4708620210488637 accuracy: 0.8197186666666667 f1 score: 0.00019225507812211154\n",
      "[13] validation loss: 0.4466002881526947 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[14] train loss: 0.4574794073899587 accuracy: 0.8171413333333334 f1 score: 0.048892464318903706\n",
      "[14] validation loss: 0.4734363853931427 accuracy: 0.865215 f1 score: 7.41867279943618e-05\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[15] train loss: 0.4533612132072449 accuracy: 0.8178826666666666 f1 score: 0.2047555835021775\n",
      "[15] validation loss: 0.4487890601158142 accuracy: 0.862015 f1 score: 0.008621618708912598\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[16] train loss: 0.45792152484258014 accuracy: 0.8154626666666667 f1 score: 0.0535446855360965\n",
      "[16] validation loss: 0.5169429779052734 accuracy: 0.767635 f1 score: 0.08956802821040258\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[17] train loss: 0.477004736661911 accuracy: 0.780516 f1 score: 0.26204682897963394\n",
      "[17] validation loss: 0.471280962228775 accuracy: 0.855185 f1 score: 0.019101161648660547\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[18] train loss: 0.4487864871819814 accuracy: 0.8163586666666667 f1 score: 0.030370657186102996\n",
      "[18] validation loss: 0.4681623876094818 accuracy: 0.865625 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[19] train loss: 0.4731342097123464 accuracy: 0.8185346666666666 f1 score: 0.10207757420614763\n",
      "[19] validation loss: 0.47828787565231323 accuracy: 0.865735 f1 score: 0.0014131121936707448\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[20] train loss: 0.44567107160886127 accuracy: 0.8213053333333333 f1 score: 0.024002854708448332\n",
      "[20] validation loss: 0.4493369162082672 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[21] train loss: 0.45283016562461853 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[21] validation loss: 0.45904168486595154 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[22] train loss: 0.43581730127334595 accuracy: 0.815472 f1 score: 0.0088518391199725\n",
      "[22] validation loss: 0.47912290692329407 accuracy: 0.865875 f1 score: 0.003640010400029714\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[23] train loss: 0.4336818257967631 accuracy: 0.817128 f1 score: 0.10245402787775669\n",
      "[23] validation loss: 0.4991665482521057 accuracy: 0.85757 f1 score: 0.019482307586396803\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[24] train loss: 0.43164345622062683 accuracy: 0.8074813333333334 f1 score: 0.21087264241172193\n",
      "[24] validation loss: 0.5169599056243896 accuracy: 0.755205 f1 score: 0.16507784921298113\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[25] train loss: 0.43410516778628033 accuracy: 0.8076653333333333 f1 score: 0.2580558884494118\n",
      "[25] validation loss: 0.5278167128562927 accuracy: 0.7912 f1 score: 0.13928851148027535\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[26] train loss: 0.4193161229292552 accuracy: 0.8226773333333334 f1 score: 0.34794418458702275\n",
      "[26] validation loss: 0.4795915186405182 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[27] train loss: 0.43011529246966046 accuracy: 0.819272 f1 score: 0.00017703031644169064\n",
      "[27] validation loss: 0.5128543972969055 accuracy: 0.865505 f1 score: 0.0003716228771043145\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[28] train loss: 0.42671342690785724 accuracy: 0.8202253333333334 f1 score: 0.005135508053745748\n",
      "[28] validation loss: 0.48776736855506897 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[29] train loss: 0.430884728829066 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[29] validation loss: 0.5173577070236206 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[30] train loss: 0.4229592978954315 accuracy: 0.8194573333333334 f1 score: 0.09298742707098312\n",
      "[30] validation loss: 0.5255939960479736 accuracy: 0.86395 f1 score: 0.029185100613672042\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[31] train loss: 0.42264729738235474 accuracy: 0.8297426666666666 f1 score: 0.19128925818729933\n",
      "[31] validation loss: 0.5190057754516602 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[32] train loss: 0.4106537302335103 accuracy: 0.818664 f1 score: 0.016360006943239018\n",
      "[32] validation loss: 0.5051873922348022 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[33] train loss: 0.4234333237012227 accuracy: 0.8178693333333333 f1 score: 0.06997739589858111\n",
      "[33] validation loss: 0.48517197370529175 accuracy: 0.86434 f1 score: 0.008550756413067311\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[34] train loss: 0.39965561032295227 accuracy: 0.827176 f1 score: 0.1291453910239183\n",
      "[34] validation loss: 0.5183901786804199 accuracy: 0.86546 f1 score: 0.004513503514613392\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[35] train loss: 0.3813210924466451 accuracy: 0.8360386666666667 f1 score: 0.2029723826375521\n",
      "[35] validation loss: 0.5773202776908875 accuracy: 0.742165 f1 score: 0.1372283290669076\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[36] train loss: 0.37817931175231934 accuracy: 0.848884 f1 score: 0.4867239403834048\n",
      "[36] validation loss: 0.6047320365905762 accuracy: 0.6453 f1 score: 0.22726678576096904\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[37] train loss: 0.3810560305913289 accuracy: 0.8528333333333333 f1 score: 0.5499031501682128\n",
      "[37] validation loss: 0.5233057737350464 accuracy: 0.74081 f1 score: 0.19750448944207072\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[38] train loss: 0.3744153678417206 accuracy: 0.847636 f1 score: 0.4733113635839882\n",
      "[38] validation loss: 0.5980991125106812 accuracy: 0.654535 f1 score: 0.2364992541024366\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[39] train loss: 0.3541070024172465 accuracy: 0.8692986666666667 f1 score: 0.5782884774229076\n",
      "[39] validation loss: 0.5962831377983093 accuracy: 0.657475 f1 score: 0.2005764764916621\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[40] train loss: 0.4469007154305776 accuracy: 0.7991093333333333 f1 score: 0.32997136097621715\n",
      "[40] validation loss: 0.48699691891670227 accuracy: 0.754175 f1 score: 0.24355719670743903\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[41] train loss: 0.4039834936459859 accuracy: 0.818736 f1 score: 0.30927751244792195\n",
      "[41] validation loss: 0.43241679668426514 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[42] train loss: 0.4261066714922587 accuracy: 0.8198506666666666 f1 score: 0.0\n",
      "[42] validation loss: 0.45736441016197205 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[43] train loss: 0.39360760649045307 accuracy: 0.8373986666666666 f1 score: 0.26803195544004754\n",
      "[43] validation loss: 0.543237566947937 accuracy: 0.76185 f1 score: 0.07525336853958761\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[44] train loss: 0.4028288722038269 accuracy: 0.83448 f1 score: 0.4586698295860878\n",
      "[44] validation loss: 0.5346767902374268 accuracy: 0.7613 f1 score: 0.06622853342721903\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[45] train loss: 0.40039095282554626 accuracy: 0.8331626666666667 f1 score: 0.42026890538274075\n",
      "[45] validation loss: 0.528445839881897 accuracy: 0.791475 f1 score: 0.07406585111342998\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[46] train loss: 0.41312764088312787 accuracy: 0.8193466666666667 f1 score: 0.3366267797340436\n",
      "[46] validation loss: 0.5826991200447083 accuracy: 0.68431 f1 score: 0.09432825544366985\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[47] train loss: 0.4019518395264943 accuracy: 0.8460333333333333 f1 score: 0.5256239088014788\n",
      "[47] validation loss: 0.5651805400848389 accuracy: 0.755375 f1 score: 0.08009777192817523\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[48] train loss: 0.3862634499867757 accuracy: 0.8468973333333333 f1 score: 0.3885122721439108\n",
      "[48] validation loss: 0.5736052989959717 accuracy: 0.76352 f1 score: 0.07779900947627033\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[49] train loss: 0.3742848038673401 accuracy: 0.8566173333333333 f1 score: 0.4730309163166999\n",
      "[49] validation loss: 0.6142950057983398 accuracy: 0.599335 f1 score: 0.11791513016676758\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[50] train loss: 0.3777077794075012 accuracy: 0.8480146666666667 f1 score: 0.49423864478372176\n",
      "[50] validation loss: 0.620916485786438 accuracy: 0.609655 f1 score: 0.12438452652003723\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[51] train loss: 0.3628003199895223 accuracy: 0.862308 f1 score: 0.508811232716428\n",
      "[51] validation loss: 0.6171776652336121 accuracy: 0.62564 f1 score: 0.105685618729097\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[52] train loss: 0.3625495831171672 accuracy: 0.85084 f1 score: 0.49894746271330676\n",
      "[52] validation loss: 0.6832930445671082 accuracy: 0.597795 f1 score: 0.16084040100564367\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[53] train loss: 0.37755274772644043 accuracy: 0.8511053333333334 f1 score: 0.5183584567941171\n",
      "[53] validation loss: 0.6395940780639648 accuracy: 0.68069 f1 score: 0.08238979251681132\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[54] train loss: 0.35167196393013 accuracy: 0.8650853333333334 f1 score: 0.5121920647929421\n",
      "[54] validation loss: 0.6393157839775085 accuracy: 0.679985 f1 score: 0.08865283572313432\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[55] train loss: 0.38495682676633197 accuracy: 0.8426306666666666 f1 score: 0.48763885934563006\n",
      "[55] validation loss: 0.7054118514060974 accuracy: 0.6305 f1 score: 0.09708476895633264\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[56] train loss: 0.3634555439154307 accuracy: 0.8587026666666666 f1 score: 0.5068293613674546\n",
      "[56] validation loss: 0.6850160956382751 accuracy: 0.59641 f1 score: 0.1749494040926467\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[57] train loss: 0.3539158006509145 accuracy: 0.868752 f1 score: 0.5469874638734974\n",
      "[57] validation loss: 0.6804494857788086 accuracy: 0.639705 f1 score: 0.13306223607117507\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[58] train loss: 0.3508494397004445 accuracy: 0.86524 f1 score: 0.5188517566409597\n",
      "[58] validation loss: 0.6498088240623474 accuracy: 0.658325 f1 score: 0.21919811698031283\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[59] train loss: 0.38348854581514996 accuracy: 0.8451346666666667 f1 score: 0.4736505807340405\n",
      "[59] validation loss: 0.725678563117981 accuracy: 0.612485 f1 score: 0.18923979789315118\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[60] train loss: 0.43997693061828613 accuracy: 0.795216 f1 score: 0.39099747815191355\n",
      "[60] validation loss: 0.654103696346283 accuracy: 0.64143 f1 score: 0.11029229318644236\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[61] train loss: 0.3797542254130046 accuracy: 0.8569466666666666 f1 score: 0.4496594033403094\n",
      "[61] validation loss: 0.5491437315940857 accuracy: 0.710405 f1 score: 0.27996369920063646\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[62] train loss: 0.3850645323594411 accuracy: 0.8404893333333333 f1 score: 0.3605419996258385\n",
      "[62] validation loss: 0.5855709910392761 accuracy: 0.6661 f1 score: 0.28719339068804306\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[63] train loss: 0.38870011766751605 accuracy: 0.850788 f1 score: 0.49168547899907794\n",
      "[63] validation loss: 0.5621572732925415 accuracy: 0.676935 f1 score: 0.23016525479262728\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[64] train loss: 0.36945035060246784 accuracy: 0.8596466666666667 f1 score: 0.4850376443768253\n",
      "[64] validation loss: 0.5188491940498352 accuracy: 0.73503 f1 score: 0.11782527633506458\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[65] train loss: 0.38709943493207294 accuracy: 0.8476266666666666 f1 score: 0.3532248205917642\n",
      "[65] validation loss: 0.5425583124160767 accuracy: 0.716565 f1 score: 0.10230098025242688\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[66] train loss: 0.3762631913026174 accuracy: 0.8444706666666667 f1 score: 0.45300095193881335\n",
      "[66] validation loss: 0.592114269733429 accuracy: 0.644095 f1 score: 0.19483060912844297\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[67] train loss: 0.36022765437761944 accuracy: 0.8590573333333333 f1 score: 0.5725711559223481\n",
      "[67] validation loss: 0.5866361856460571 accuracy: 0.62289 f1 score: 0.13568334441108384\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[68] train loss: 0.34139005343119305 accuracy: 0.8639613333333334 f1 score: 0.5408504452934797\n",
      "[68] validation loss: 0.5796874761581421 accuracy: 0.68006 f1 score: 0.11440197082514461\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[69] train loss: 0.3364364306131999 accuracy: 0.87034 f1 score: 0.5527505530541004\n",
      "[69] validation loss: 0.652398407459259 accuracy: 0.64412 f1 score: 0.11009977244880097\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[70] train loss: 0.3384406665960948 accuracy: 0.8643133333333334 f1 score: 0.5830072322727365\n",
      "[70] validation loss: 0.6845135688781738 accuracy: 0.587345 f1 score: 0.14980478608881975\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[71] train loss: 0.32764874895413715 accuracy: 0.8662773333333333 f1 score: 0.5661172398875188\n",
      "[71] validation loss: 0.6583450436592102 accuracy: 0.62726 f1 score: 0.1479449549673113\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[72] train loss: 0.34272042910257977 accuracy: 0.8572826666666666 f1 score: 0.5131006750486726\n",
      "[72] validation loss: 0.6695151925086975 accuracy: 0.657605 f1 score: 0.13822785447315103\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[73] train loss: 0.3163998524347941 accuracy: 0.8742666666666666 f1 score: 0.6199358364635896\n",
      "[73] validation loss: 0.7294145822525024 accuracy: 0.59668 f1 score: 0.17147024384231396\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[74] train loss: 0.3366391956806183 accuracy: 0.859972 f1 score: 0.5997477009150606\n",
      "[74] validation loss: 0.6809504628181458 accuracy: 0.66622 f1 score: 0.12666474790025903\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[75] train loss: 0.3336428205172221 accuracy: 0.876188 f1 score: 0.5754415482879859\n",
      "[75] validation loss: 0.6849316358566284 accuracy: 0.65911 f1 score: 0.088261253309797\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[76] train loss: 0.3177683154741923 accuracy: 0.8767093333333333 f1 score: 0.5887167078833597\n",
      "[76] validation loss: 0.734433114528656 accuracy: 0.583395 f1 score: 0.11953546859974849\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[77] train loss: 0.3568310836950938 accuracy: 0.8528546666666666 f1 score: 0.5152102195103737\n",
      "[77] validation loss: 0.6727027893066406 accuracy: 0.63958 f1 score: 0.13968587387215353\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[78] train loss: 0.35124701261520386 accuracy: 0.850256 f1 score: 0.5111432252672633\n",
      "[78] validation loss: 0.6316247582435608 accuracy: 0.67256 f1 score: 0.11987958284055479\n",
      "\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([10, 25000, 2])\n",
      "12 torch.Size([8, 25000, 2])\n",
      "[79] train loss: 0.3351934452851613 accuracy: 0.862872 f1 score: 0.5129106202402152\n",
      "[79] validation loss: 0.6448060870170593 accuracy: 0.633275 f1 score: 0.17527801828342685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "loss_func = CustomLoss()\n",
    "classifier = PoinNet(input_dim=4, num_classes=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "\n",
    "num_batch = len(training_data)\n",
    "\n",
    "for epoch in range(80):\n",
    "    classifier.train()\n",
    "    train_loss, train_f1, train_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    for i, data in enumerate(train_dataloader, 1):\n",
    "        points, target = data\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "        # print(pred.size(), target.size())\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "        labels = np.append(labels, target.cpu())\n",
    "\n",
    "    train_f1 = f1_score(predictions, labels)\n",
    "    train_acc = sum(predictions == labels)/float(len(labels))\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    classifier.eval()\n",
    "    valid_loss, valid_f1, valid_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    for i, data in enumerate(validation_dataloader):\n",
    "        points, target = data\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        pred,  trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "        predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "        labels = np.append(labels, target.cpu())\n",
    "\n",
    "    valid_f1 = f1_score(predictions, labels)\n",
    "    valid_acc = sum(predictions == labels)/float(len(labels))\n",
    "    valid_loss /= len(validation_dataloader)\n",
    "\n",
    "    writer.add_scalars('losses', {'training':train_loss, 'validation':valid_loss}, global_step=epoch)\n",
    "    writer.add_scalars('f1 scores', {'training':train_f1, 'validation':valid_f1}, global_step=epoch)\n",
    "\n",
    "    print(f'[{epoch}] train loss: {train_loss} accuracy: {train_acc} f1 score: {train_f1}')\n",
    "    print(f'[{epoch}] validation loss: {valid_loss} accuracy: {valid_acc} f1 score: {valid_f1}')\n",
    "    print()\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825faa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 torch.Size([8, 25000, 2])\n",
      "F1 score:  0.08487002888247056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs = None\n",
    "points = None\n",
    "x = y = None\n",
    "def test_PointNet(pointnet, test_dataloader, device):\n",
    "    global outputs, points, x, y\n",
    "    pointnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (points, labels) in enumerate(test_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            outputs, _ = pointnet(points)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            x = labels.view(-1).to('cpu').numpy()\n",
    "            y = predicted.view(-1).to('cpu').numpy()\n",
    "            f1 = f1_score(x, y)\n",
    "            print('F1 score: ', f1)\n",
    "    \n",
    "test_PointNet(classifier, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20bd5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26763\n",
      "27249\n",
      "tensor([[[-0.2036, -1.6916],\n",
      "         [-0.1744, -1.8326],\n",
      "         [-0.1006, -2.3463],\n",
      "         ...,\n",
      "         [-0.0214, -3.8572],\n",
      "         [-0.0180, -4.0255],\n",
      "         [-0.0160, -4.1438]],\n",
      "\n",
      "        [[-0.0083, -4.8015],\n",
      "         [-0.0083, -4.7998],\n",
      "         [-0.0172, -4.0712],\n",
      "         ...,\n",
      "         [-0.0080, -4.8382],\n",
      "         [-0.0080, -4.8365],\n",
      "         [-0.0080, -4.8377]],\n",
      "\n",
      "        [[-0.0078, -4.8599],\n",
      "         [-0.0078, -4.8592],\n",
      "         [-0.0078, -4.8586],\n",
      "         ...,\n",
      "         [-0.6657, -0.7214],\n",
      "         [-0.6377, -0.7519],\n",
      "         [-0.6069, -0.7875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0210, -3.8739],\n",
      "         [-0.0210, -3.8740],\n",
      "         [-0.0210, -3.8737],\n",
      "         ...,\n",
      "         [-0.3783, -1.1554],\n",
      "         [-0.2735, -1.4302],\n",
      "         [-0.2660, -1.4542]],\n",
      "\n",
      "        [[-0.2603, -1.4732],\n",
      "         [-0.2593, -1.4766],\n",
      "         [-0.2497, -1.5096],\n",
      "         ...,\n",
      "         [-0.0239, -3.7439],\n",
      "         [-0.0241, -3.7394],\n",
      "         [-0.0241, -3.7374]],\n",
      "\n",
      "        [[-0.0128, -4.3645],\n",
      "         [-0.0128, -4.3621],\n",
      "         [-0.0286, -3.5669],\n",
      "         ...,\n",
      "         [-0.2839, -1.3976],\n",
      "         [-0.2929, -1.3707],\n",
      "         [-0.1286, -2.1143]]])\n"
     ]
    }
   ],
   "source": [
    "print(sum(x))\n",
    "print(sum(y))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbbe45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels has 173237 zeroes and 26763 ones\n",
      "Predictions has 172751 zeroes and 27249 ones\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels has {sum(x == 0)} zeroes and {sum(x == 1)} ones\")\n",
    "print(f\"Predictions has {sum(y == 0)} zeroes and {sum(y == 1)} ones\")\n",
    "\n",
    "\n",
    "# writer.add_graph(model, points)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c64757",
   "metadata": {},
   "source": [
    "73.4029268292683% on roofs (5)\n",
    "86.77414634146342% on trees (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

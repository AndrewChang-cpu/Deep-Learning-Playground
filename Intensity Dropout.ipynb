{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.transforms import ToTensorfrom\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669251ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file points shape (753876, 5)\n",
      "(205861, 5)\n",
      "(205861, 5)\n"
     ]
    }
   ],
   "source": [
    "class KDTreeDataset(Dataset):\n",
    "    def __init__(self, pts_file, split=0):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "        # points = np.delete(points, -2, 1)\n",
    "\n",
    "        if split == 1:\n",
    "            points = points[:len(points)//2]\n",
    "        elif split == 2:\n",
    "            points = points[len(points)//2:]\n",
    "\n",
    "        print('file points shape', points.shape)\n",
    "        \n",
    "        # Scale x, y, z from 0-1 and intensity from 0-1 based on intensity range 1-256\n",
    "        self.dim_scalars = []\n",
    "        for i in range(4):\n",
    "            if i == 3:\n",
    "                points[:,i] = points[:,i] / 255\n",
    "            else:\n",
    "                dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "                points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "                self.dim_scalars.append(dim_max - dim_min)\n",
    "        self.data = points\n",
    "\n",
    "        self.tree = KDTree(self.data[:, :3])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 15000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 25000 points\n",
    "        pc_size = 25000\n",
    "\n",
    "        # print('Starting point', self.data[idx * 10000, :3])\n",
    "        noisy_point = self.data[idx * 15000, :3] + np.random.normal(0, 0.01, 3)[0]\n",
    "        # print('Noisy point', noisy_point)\n",
    "        \n",
    "        _, indicies = self.tree.query(noisy_point, k=pc_size)\n",
    "        \n",
    "        # Drop random intensities\n",
    "\n",
    "        xyzirn = self.data[indicies, :-1]  # x, y, z, ***intensity, return number, number of returns***\n",
    "        label = self.data[indicies, -1] == 5\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            random_indices = np.random.choice(pc_size, pc_size//10, replace=False)\n",
    "            xyzirn[random_indices, 3] = 0\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float() # intensity, z, y, x from top to bottom? or other way around\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        # print(xyzirn.size(), label.size())\n",
    "\n",
    "        return xyzirn, label\n",
    "\n",
    "class NormalDataset(Dataset):\n",
    "    def __init__(self, pts_file, split=0):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "        # points = np.delete(points, -2, 1)\n",
    "\n",
    "        if split == 1:\n",
    "            points = points[:len(points)//2]\n",
    "        elif split == 2:\n",
    "            points = points[len(points)//2:]\n",
    "\n",
    "        print(points.shape)\n",
    "        # do i need to min max intensity, return number, number of returns, etc.? probably not\n",
    "        self.dim_scalars = []\n",
    "        for i in range(4):\n",
    "            dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "            points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "            self.dim_scalars.append(dim_max - dim_min)\n",
    "        self.data = points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 25000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 25000 points\n",
    "        xyzirn = self.data[idx * 25000: (idx + 1) * 25000, :-1]  # x, y, z, ***intensity, return number, number of returns***\n",
    "        label = self.data[idx * 25000: (idx + 1) * 25000, -1] == 5\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float() # intensity, z, y, x from top to bottom\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return xyzirn, label\n",
    "\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), r\"data\\Point Cloud\")\n",
    "training_data = KDTreeDataset(os.path.join(data_folder, r\"Traininig.pts\"))\n",
    "validation_data = NormalDataset(os.path.join(data_folder, r\"Testing.pts\"), split=1)\n",
    "testing_data = NormalDataset(os.path.join(data_folder, r\"Testing.pts\"), split=2)\n",
    "train_dataloader = DataLoader(training_data, batch_size=5, shuffle=True) # can/should i use shuffle, try lowering it?\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=5, shuffle=False)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=5, shuffle=False)\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc807f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97740441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 25000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n",
      "torch.Size([5, 4, 25000])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    print(data[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d56a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "def plot_view(entire_view = True):\n",
    "    # Assuming pc is your point cloud data, in shape (N, 3)\n",
    "    pc_num = 2\n",
    "\n",
    "    if entire_view:\n",
    "        pc = training_data.data[:, :3]\n",
    "        labels = training_data.data[:, -1] == 5\n",
    "    else:\n",
    "        pc, labels = training_data[pc_num]\n",
    "        pc = pc.T.numpy()[:, :3]\n",
    "        labels = labels.numpy()\n",
    "\n",
    "    pc = copy.deepcopy(pc)\n",
    "    for i in range(3):\n",
    "        pc[:, i] *= training_data.dim_scalars[i]\n",
    "\n",
    "    print(Counter(labels), len(labels))\n",
    "\n",
    "    # Define colors for each label\n",
    "    color_map = {0: [0.5, 0.5, 0.5],  # Gray color for label 0\n",
    "                1: [1.0, 0.0, 0.0]}  # Red color for label 1\n",
    "\n",
    "    # Map each label to a color\n",
    "    colors = np.array([color_map[label] for label in labels])\n",
    "\n",
    "    # Create point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pc)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "# plot_view(entire_view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66c21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(data, labels):\n",
    "    pc, labels = data.transpose(1,2).reshape(-1, 4).numpy()[:, :3], labels.view(-1).numpy()\n",
    "    # print(labels.shape)\n",
    "    pc = copy.deepcopy(pc)\n",
    "    for i in range(3):\n",
    "        pc[:, i] *= training_data.dim_scalars[i]\n",
    "\n",
    "    print(Counter(list(labels)), len(labels))\n",
    "\n",
    "    # Define colors for each label\n",
    "    color_map = {0: [0.5, 0.5, 0.5],  # Gray color for label 0\n",
    "                1: [1.0, 0.0, 0.0]}  # Red color for label 1\n",
    "\n",
    "    # Map each label to a color\n",
    "    colors = np.array([color_map[label] for label in labels])\n",
    "\n",
    "    # Create point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pc)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "# for i, data in enumerate(train_dataloader):\n",
    "#     print(data[0].size())\n",
    "#     plot_batch(*data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4086ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\\\n",
    "try:\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "except:\n",
    "    device = 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.mlp1 = nn.Sequential(torch.nn.Conv1d(k, 64, 1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(torch.nn.Conv1d(64, 128, 1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp3 = nn.Sequential(torch.nn.Conv1d(128, 1024, 1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Linear(512, 256), nn.BatchNorm1d(256), nn.GELU())\n",
    "        self.fc = nn.Linear(256, k*k)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.mlp3(x)\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = self.mlp4(x)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        iden = torch.eye(self.k, requires_grad=True).repeat(batchsize,1,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x.view(-1, self.k, self.k) + iden\n",
    "\n",
    "        return x\n",
    "    \n",
    "class PoinNet(nn.Module):\n",
    "    def __init__(self, input_dim=6, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Should GELU be after LayerNorm?\n",
    "        self.stn1 = STNkd(k=input_dim)\n",
    "        self.mlp1 = nn.Sequential(nn.Conv1d(input_dim, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        \n",
    "        self.stn2 = STNkd(k=64)\n",
    "        self.mlp3 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        \n",
    "        self.mlp6 = nn.Sequential(nn.Linear(1088, 512), nn.LayerNorm(512), nn.GELU())\n",
    "        self.mlp7 = nn.Sequential(nn.Linear(512, 256), nn.LayerNorm(256), nn.GELU())\n",
    "        self.mlp8 = nn.Sequential(nn.Linear(256, 128), nn.LayerNorm(128), nn.GELU())\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.debug = nn.Conv1d(input_dim, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "\n",
    "        trans6x6 = self.stn1(x) \n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans6x6)\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "        # print(1, x.size())\n",
    "        x = self.mlp2(x)\n",
    "        # print(2, x.size())\n",
    "        \n",
    "        \n",
    "        trans64x64 = self.stn2(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans64x64)\n",
    "        local_features = x.transpose(2, 1)\n",
    "        \n",
    "        x = self.mlp3(local_features)\n",
    "        # print(3, x.size())\n",
    "        x = self.mlp4(x)\n",
    "        # print(4, x.size())\n",
    "        x = self.mlp5(x)\n",
    "        # print(5, x.size())\n",
    "        x = torch.max(x, 2)[0]\n",
    "        # print(6, x.size())\n",
    "        \n",
    "        # FOR CLASSIFICATION\n",
    "        # x = self.mlp6(x)\n",
    "        # print(6, x.size())\n",
    "        # x = self.mlp7(x)\n",
    "        # print(7, x.size())\n",
    "        # x = self.fc(x)\n",
    "        # print(8, x.size())\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "\n",
    "        global_features = x.unsqueeze(2).repeat(1, 1, n_pts)\n",
    "        # print(7, global_features.size())\n",
    "        x = torch.cat([local_features, global_features], 1)\n",
    "        # print(8, x.size())\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.mlp6(x)\n",
    "        # print(9, x.size())\n",
    "        x = self.mlp7(x)\n",
    "        # print(10, x.size())\n",
    "        x = self.mlp8(x)\n",
    "        # print(11, x.size())\n",
    "        x = self.fc(x)\n",
    "        # print(12, x.size())\n",
    "\n",
    "        # x = x.view(-1, 2)\n",
    "        # print(13, x.size())\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        # print(14, x.size())\n",
    "\n",
    "        return x, trans64x64\n",
    "\n",
    "# model = PoinNet(input_dim=6, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size(1)\n",
    "    I = torch.eye(d).unsqueeze(0).to(device)\n",
    "    loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cad6a3",
   "metadata": {},
   "source": [
    "## Online Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294c68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[0] train loss: 0.5828735202550888 accuracy: 0.7894568 f1 score: 0.03800054829571415\n",
      "[0] validation loss: 0.6412931382656097 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[1] train loss: 0.4813381791114807 accuracy: 0.8708784 f1 score: 0.0\n",
      "[1] validation loss: 0.7773136794567108 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[2] train loss: 0.4538294792175293 accuracy: 0.876932 f1 score: 0.0\n",
      "[2] validation loss: 0.8373446464538574 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[3] train loss: 0.4709355622529984 accuracy: 0.8682792 f1 score: 0.0\n",
      "[3] validation loss: 0.6925681233406067 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[4] train loss: 0.4201526314020157 accuracy: 0.875436 f1 score: 0.0\n",
      "[4] validation loss: 1.0043375790119171 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[5] train loss: 0.4488139390945435 accuracy: 0.8588968 f1 score: 0.018103779414466323\n",
      "[5] validation loss: 1.1975568234920502 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[6] train loss: 0.39302205145359037 accuracy: 0.8831312 f1 score: 0.0\n",
      "[6] validation loss: 1.7446636259555817 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[7] train loss: 0.40679762661457064 accuracy: 0.8715256 f1 score: 0.0\n",
      "[7] validation loss: 1.9008492231369019 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[8] train loss: 0.3536734774708748 accuracy: 0.8739536 f1 score: 0.0\n",
      "[8] validation loss: 1.2594985961914062 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[9] train loss: 0.3629680275917053 accuracy: 0.8782432 f1 score: 0.0\n",
      "[9] validation loss: 1.2978623509407043 accuracy: 0.70891 f1 score: 0.005262618323480163\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[10] train loss: 0.35113377273082735 accuracy: 0.876304 f1 score: 0.16536215142453065\n",
      "[10] validation loss: 1.1519739925861359 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[11] train loss: 0.33394323736429216 accuracy: 0.876788 f1 score: 0.2721167524445516\n",
      "[11] validation loss: 1.4513713121414185 accuracy: 0.76255 f1 score: 0.5566405885318445\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[12] train loss: 0.41944760978221896 accuracy: 0.866908 f1 score: 0.1444550152991695\n",
      "[12] validation loss: 1.4948008060455322 accuracy: 0.67469 f1 score: 0.5441219748034586\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[13] train loss: 0.3450308158993721 accuracy: 0.8828776 f1 score: 0.4635228676020623\n",
      "[13] validation loss: 1.2819606363773346 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[14] train loss: 0.3330752670764923 accuracy: 0.8798648 f1 score: 0.0\n",
      "[14] validation loss: 0.8180016875267029 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[15] train loss: 0.3740760892629623 accuracy: 0.8682288 f1 score: 0.0\n",
      "[15] validation loss: 0.7623327374458313 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[16] train loss: 0.3314854115247726 accuracy: 0.8750672 f1 score: 0.0\n",
      "[16] validation loss: 0.7665582895278931 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[17] train loss: 0.31309026628732683 accuracy: 0.8835976 f1 score: 0.2864316925687439\n",
      "[17] validation loss: 0.9199075102806091 accuracy: 0.523985 f1 score: 0.47483768472498794\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[18] train loss: 0.2930887758731842 accuracy: 0.8853904 f1 score: 0.3624753021591698\n",
      "[18] validation loss: 0.9167740046977997 accuracy: 0.453085 f1 score: 0.47512200271597\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[19] train loss: 0.3525982588529587 accuracy: 0.8543256 f1 score: 0.36228326078048884\n",
      "[19] validation loss: 0.7774097621440887 accuracy: 0.71611 f1 score: 0.06272904354716234\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[20] train loss: 0.3643146723508835 accuracy: 0.8744432 f1 score: 0.03263067061143984\n",
      "[20] validation loss: 0.8237828314304352 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[21] train loss: 0.39835400581359864 accuracy: 0.8734328 f1 score: 0.0\n",
      "[21] validation loss: 0.7405430972576141 accuracy: 0.747765 f1 score: 0.33073749286917764\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[22] train loss: 0.36171203553676606 accuracy: 0.8741816 f1 score: 0.3595150537765778\n",
      "[22] validation loss: 0.8541426658630371 accuracy: 0.76156 f1 score: 0.4369775678866588\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[23] train loss: 0.3094901889562607 accuracy: 0.8915104 f1 score: 0.40047215271576236\n",
      "[23] validation loss: 0.7142921984195709 accuracy: 0.58658 f1 score: 0.5124131668022975\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[24] train loss: 0.27383175790309905 accuracy: 0.903872 f1 score: 0.5292605912449365\n",
      "[24] validation loss: 0.6717501580715179 accuracy: 0.71002 f1 score: 0.5228787205686363\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[25] train loss: 0.3715278938412666 accuracy: 0.829196 f1 score: 0.24909172121028808\n",
      "[25] validation loss: 0.880789041519165 accuracy: 0.515405 f1 score: 0.5063389141585212\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[26] train loss: 0.3160607904195786 accuracy: 0.866484 f1 score: 0.2327407468704171\n",
      "[26] validation loss: 0.7708231508731842 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[27] train loss: 0.3770026430487633 accuracy: 0.8721824 f1 score: 0.0\n",
      "[27] validation loss: 0.7346124649047852 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[28] train loss: 0.37235167622566223 accuracy: 0.8735512 f1 score: 0.0\n",
      "[28] validation loss: 0.6539752781391144 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[29] train loss: 0.3568536892533302 accuracy: 0.8748704 f1 score: 0.0\n",
      "[29] validation loss: 0.6723694205284119 accuracy: 0.708295 f1 score: 0.0\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n",
      "[30] train loss: 0.3027462989091873 accuracy: 0.876384 f1 score: 0.03095524784266506\n",
      "[30] validation loss: 0.6969299614429474 accuracy: 0.71842 f1 score: 0.11602938406479561\n",
      "\n",
      "Iteration 1 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 2 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 3 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 4 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 5 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 6 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 7 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 8 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 9 torch.Size([125000, 2]) torch.Size([125000])\n",
      "Iteration 10 torch.Size([125000, 2]) torch.Size([125000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "classifier = PoinNet(input_dim=4, num_classes=2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "\n",
    "num_batch = len(training_data)\n",
    "\n",
    "for epoch in range(120):\n",
    "    classifier.train()\n",
    "    train_loss, train_f1, train_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    for i, data in enumerate(train_dataloader, 1):\n",
    "        points, target = data\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "        print(f'Iteration {i}', pred.size(), target.size())\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += float(loss) # JUST USING LOSS ACCUMULATES HISTORY\n",
    "\n",
    "        predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "        labels = np.append(labels, target.cpu())\n",
    "\n",
    "    train_f1 = f1_score(predictions, labels)\n",
    "    train_acc = sum(predictions == labels)/float(len(labels))\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "\n",
    "    classifier.eval()\n",
    "    valid_loss, valid_f1, valid_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader):\n",
    "            points, target = data\n",
    "            points, target = points.to(device), target.to(device)\n",
    "            pred,  trans_feat = classifier(points)\n",
    "            pred = pred.view(-1, num_classes)\n",
    "            target = target.view(-1, 1).squeeze()\n",
    "\n",
    "            loss = F.nll_loss(pred, target)\n",
    "            loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "            valid_loss += float(loss)\n",
    "\n",
    "            predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "            labels = np.append(labels, target.cpu())\n",
    "\n",
    "    valid_f1 = f1_score(predictions, labels)\n",
    "    valid_acc = sum(predictions == labels)/float(len(labels))\n",
    "    valid_loss /= len(validation_dataloader)\n",
    "\n",
    "\n",
    "    writer.add_scalars('losses', {'training':train_loss, 'validation':valid_loss}, global_step=epoch)\n",
    "    writer.add_scalars('f1 scores', {'training':train_f1, 'validation':valid_f1}, global_step=epoch)\n",
    "\n",
    "    print(f'[{epoch}] train loss: {train_loss} accuracy: {train_acc} f1 score: {train_f1}')\n",
    "    print(f'[{epoch}] validation loss: {valid_loss} accuracy: {valid_acc} f1 score: {valid_f1}')\n",
    "    print()\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825faa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_9092\\1842858222.py\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mplot_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtest_PointNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_9092\\1842858222.py\u001b[0m in \u001b[0;36mtest_PointNet\u001b[1;34m(pointnet, test_dataloader, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mplot_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mplot_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_9092\\3063570382.py\u001b[0m in \u001b[0;36mplot_batch\u001b[1;34m(data, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# print(labels.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs = None\n",
    "points = None\n",
    "x = y = None\n",
    "def test_PointNet(pointnet, test_dataloader, device):\n",
    "    global outputs, points, x, y\n",
    "    pointnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (points, labels) in enumerate(test_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            outputs, _ = pointnet(points)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            x = labels.view(-1).to('cpu').numpy()\n",
    "            y = predicted.view(-1).to('cpu').numpy()\n",
    "            f1 = f1_score(x, y)\n",
    "            print('F1 score: ', f1)\n",
    "            plot_batch(points, predicted)\n",
    "            plot_batch(points, labels)\n",
    "    \n",
    "test_PointNet(classifier, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20070\n",
      "20965\n",
      "tensor([[[-0.0199, -3.9263],\n",
      "         [-0.0199, -3.9261],\n",
      "         [-0.0199, -3.9259],\n",
      "         ...,\n",
      "         [-0.3394, -1.2456],\n",
      "         [-0.1242, -2.1474],\n",
      "         [-0.1215, -2.1678]],\n",
      "\n",
      "        [[-0.1984, -1.7152],\n",
      "         [-0.1861, -1.7731],\n",
      "         [-0.1867, -1.7700],\n",
      "         ...,\n",
      "         [-0.0231, -3.7794],\n",
      "         [-0.0232, -3.7755],\n",
      "         [-0.0233, -3.7693]],\n",
      "\n",
      "        [[-0.0218, -3.8362],\n",
      "         [-0.0219, -3.8333],\n",
      "         [-0.0320, -3.4593],\n",
      "         ...,\n",
      "         [-1.0450, -0.4334],\n",
      "         [-1.0428, -0.4346],\n",
      "         [-1.0892, -0.4102]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum(x))\n",
    "print(sum(y))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels has 54930 zeroes and 20070 ones\n",
      "Predictions has 54035 zeroes and 20965 ones\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels has {sum(x == 0)} zeroes and {sum(x == 1)} ones\")\n",
    "print(f\"Predictions has {sum(y == 0)} zeroes and {sum(y == 1)} ones\")\n",
    "\n",
    "\n",
    "# writer.add_graph(model, points)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c64757",
   "metadata": {},
   "source": [
    "73.4029268292683% on roofs (5)\n",
    "86.77414634146342% on trees (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

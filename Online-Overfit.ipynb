{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.transforms import ToTensorfrom \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669251ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753876, 4)\n",
      "(205861, 4)\n",
      "(205861, 4)\n"
     ]
    }
   ],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, pts_file, split=0):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "\n",
    "        if split == 1:\n",
    "            points = points[:len(points)//2]\n",
    "        elif split == 2:\n",
    "            points = points[len(points)//2:]\n",
    "\n",
    "        print(points.shape)\n",
    "        # do i need to min max intensity, return number, number of returns, etc.? probably not\n",
    "        for i in range(3):\n",
    "            dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "            points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "        self.data = points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 25000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 2500 points\n",
    "        xyzirn = self.data[idx * 25000: (idx + 1) * 25000, :-1]  # x, y, z, ***intensity, return number, number of returns***\n",
    "        label = self.data[idx * 25000: (idx + 1) * 25000, -1] == 8\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float()\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return xyzirn, label\n",
    "\n",
    "training_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_Traininig.pts\")\n",
    "validation_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\", split=1)\n",
    "testing_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\", split=2)\n",
    "train_dataloader = DataLoader(training_data, batch_size=10, shuffle=True) # can/should i use shuffle, try lowering it?\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=10, shuffle=False)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=10, shuffle=False)\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 25000])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader))[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97740441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 25000])\n",
      "torch.Size([10, 25000])\n",
      "torch.Size([10, 25000])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    print(data[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2f1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 3, 25000])\n",
      "Labels batch shape: torch.Size([10, 25000])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d56a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def plot_batch(entire_view = True):\n",
    "    # Assuming pc is your point cloud data, in shape (N, 3)\n",
    "    pc_num = 0\n",
    "\n",
    "    if entire_view:\n",
    "        pc = training_data.data[:, :3]\n",
    "        labels = training_data.data[:, 3] == 8\n",
    "    else:\n",
    "        pc = training_data[pc_num][0].T.view(-1,3).numpy()\n",
    "        labels = training_data[pc_num][1].numpy()\n",
    "\n",
    "    print(Counter(labels), len(labels))\n",
    "\n",
    "    # Define colors for each label\n",
    "    color_map = {0: [0.5, 0.5, 0.5],  # Gray color for label 0\n",
    "                1: [1.0, 0.0, 0.0]}  # Red color for label 1\n",
    "\n",
    "    # Map each label to a color\n",
    "    colors = np.array([color_map[label] for label in labels])\n",
    "\n",
    "    # Create point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pc)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "# plot_batch(entire_view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4086ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = True):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        print('AFTER MAXPOOL:', x.size())\n",
    "        x = x.view(-1, 1024)\n",
    "        print('AFTER RESHAPE:', x.size())\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=True):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        print(x.size())\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "    \n",
    "# model = PointNetDenseCls(k=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20254b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if name == 'mlp8.1':\n",
    "#         print(name)\n",
    "#     # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size(1)\n",
    "    I = torch.eye(d).unsqueeze(0).to(device)\n",
    "    loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e075a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, trans):\n",
    "        d = trans.size(1)\n",
    "        I = torch.eye(d).unsqueeze(0).to(device)\n",
    "        loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "        loss = torch.mean(loss)\n",
    "        return self.cross_entropy_loss(inputs, targets) + loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cad6a3",
   "metadata": {},
   "source": [
    "## Online Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294c68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[0] train loss: 0.878406802813212 accuracy: 0.46159466666666665 f1 score: 0.2947615870676135\n",
      "[0] validation loss: 0.6651950478553772 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[1] train loss: 0.8077305952707926 accuracy: 0.5614546666666667 f1 score: 0.3399338145724337\n",
      "[1] validation loss: 0.6592779755592346 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[2] train loss: 0.7422040700912476 accuracy: 0.694816 f1 score: 0.3695934780213727\n",
      "[2] validation loss: 0.6463310718536377 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[3] train loss: 0.7042587598164877 accuracy: 0.7586546666666667 f1 score: 0.27666707959863013\n",
      "[3] validation loss: 0.6383600234985352 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[4] train loss: 0.6561222076416016 accuracy: 0.8114386666666666 f1 score: 0.3238976722394596\n",
      "[4] validation loss: 0.6228973269462585 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[5] train loss: 0.6236454447110494 accuracy: 0.8176333333333333 f1 score: 0.17372970948390953\n",
      "[5] validation loss: 0.5799880623817444 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[6] train loss: 0.5966378251711527 accuracy: 0.8078413333333333 f1 score: 0.1702850365866998\n",
      "[6] validation loss: 0.526854932308197 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[7] train loss: 0.5730747779210409 accuracy: 0.8020573333333333 f1 score: 0.1977075350868186\n",
      "[7] validation loss: 0.504353940486908 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[8] train loss: 0.5453314781188965 accuracy: 0.8188413333333333 f1 score: 0.22141232156876228\n",
      "[8] validation loss: 0.5079532265663147 accuracy: 0.86571 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[9] train loss: 0.5384353399276733 accuracy: 0.8045973333333334 f1 score: 0.0963732103439346\n",
      "[9] validation loss: 0.4941006302833557 accuracy: 0.865685 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[10] train loss: 0.5322545766830444 accuracy: 0.8108146666666667 f1 score: 0.06143791714348082\n",
      "[10] validation loss: 0.48396891355514526 accuracy: 0.86533 f1 score: 0.0\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[11] train loss: 0.5133953193823496 accuracy: 0.8187466666666666 f1 score: 0.2682979341823388\n",
      "[11] validation loss: 0.5053820610046387 accuracy: 0.85832 f1 score: 0.0021832523417142057\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[12] train loss: 0.49896130959192914 accuracy: 0.8180306666666667 f1 score: 0.2039883115292416\n",
      "[12] validation loss: 0.5104098320007324 accuracy: 0.805215 f1 score: 0.019579715615955704\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[13] train loss: 0.49550944566726685 accuracy: 0.8096093333333333 f1 score: 0.11629792369341214\n",
      "[13] validation loss: 0.49882379174232483 accuracy: 0.81163 f1 score: 0.03166606693055055\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[14] train loss: 0.4805131256580353 accuracy: 0.8126253333333333 f1 score: 0.0704453601973793\n",
      "[14] validation loss: 0.4989718794822693 accuracy: 0.81451 f1 score: 0.024045038408923497\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[15] train loss: 0.4793833792209625 accuracy: 0.8122613333333333 f1 score: 0.06737494701144553\n",
      "[15] validation loss: 0.5089556574821472 accuracy: 0.83959 f1 score: 0.02905393136008716\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[16] train loss: 0.45581045746803284 accuracy: 0.8280106666666667 f1 score: 0.20272943037974683\n",
      "[16] validation loss: 0.4923548400402069 accuracy: 0.859705 f1 score: 0.026168743275604762\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[17] train loss: 0.4698108732700348 accuracy: 0.8223946666666667 f1 score: 0.1972664489146549\n",
      "[17] validation loss: 0.5057724714279175 accuracy: 0.86136 f1 score: 0.002876869965477561\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[18] train loss: 0.44738662242889404 accuracy: 0.83164 f1 score: 0.21016088272825081\n",
      "[18] validation loss: 0.5187222957611084 accuracy: 0.86013 f1 score: 0.020175131348511382\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[19] train loss: 0.4474898080031077 accuracy: 0.830244 f1 score: 0.22397493645733652\n",
      "[19] validation loss: 0.53416907787323 accuracy: 0.861195 f1 score: 0.017483631215714033\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[20] train loss: 0.45177855094273883 accuracy: 0.81076 f1 score: 0.1515524682870841\n",
      "[20] validation loss: 0.5160949230194092 accuracy: 0.859615 f1 score: 0.024528367439113366\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[21] train loss: 0.4384135405222575 accuracy: 0.8308933333333334 f1 score: 0.3480183005192001\n",
      "[21] validation loss: 0.48677822947502136 accuracy: 0.836485 f1 score: 0.037439293598234\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[22] train loss: 0.45526476701100665 accuracy: 0.8216533333333333 f1 score: 0.23135271807838179\n",
      "[22] validation loss: 0.48039302229881287 accuracy: 0.86103 f1 score: 0.014117480136208853\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[23] train loss: 0.4343909025192261 accuracy: 0.8141186666666667 f1 score: 0.08851316451889192\n",
      "[23] validation loss: 0.4797861874103546 accuracy: 0.861625 f1 score: 0.0015153155103366162\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[24] train loss: 0.4416896402835846 accuracy: 0.8207626666666666 f1 score: 0.2891093507070408\n",
      "[24] validation loss: 0.4816431999206543 accuracy: 0.864335 f1 score: 0.003306027991036991\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[25] train loss: 0.41251272956530255 accuracy: 0.8380106666666667 f1 score: 0.280175376229411\n",
      "[25] validation loss: 0.5044093728065491 accuracy: 0.86161 f1 score: 0.001443105563171946\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[26] train loss: 0.3986924688021342 accuracy: 0.829528 f1 score: 0.3674289276561217\n",
      "[26] validation loss: 0.4894450902938843 accuracy: 0.86169 f1 score: 0.012635636778983437\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[27] train loss: 0.41651169459025067 accuracy: 0.8354826666666667 f1 score: 0.37942342124851625\n",
      "[27] validation loss: 0.5226167440414429 accuracy: 0.86145 f1 score: 0.004240333477073452\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[28] train loss: 0.39661674698193866 accuracy: 0.8442026666666667 f1 score: 0.4125466300664635\n",
      "[28] validation loss: 0.5806273818016052 accuracy: 0.8593 f1 score: 0.025015591435104984\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[29] train loss: 0.3985149761041005 accuracy: 0.8313133333333333 f1 score: 0.3532515067708839\n",
      "[29] validation loss: 0.6411627531051636 accuracy: 0.86088 f1 score: 0.0649280817314155\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[30] train loss: 0.39959510167439777 accuracy: 0.8394213333333334 f1 score: 0.3616346867380472\n",
      "[30] validation loss: 0.631354570388794 accuracy: 0.84937 f1 score: 0.08040293040293041\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[31] train loss: 0.39556342363357544 accuracy: 0.834852 f1 score: 0.36633941954990307\n",
      "[31] validation loss: 0.5873585343360901 accuracy: 0.861705 f1 score: 0.0693785538844588\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[32] train loss: 0.3767339785893758 accuracy: 0.8382253333333334 f1 score: 0.39206529745113466\n",
      "[32] validation loss: 0.5932508707046509 accuracy: 0.86007 f1 score: 0.07202069102725644\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[33] train loss: 0.36437241236368817 accuracy: 0.8560866666666667 f1 score: 0.4581712306418011\n",
      "[33] validation loss: 0.5947814583778381 accuracy: 0.84486 f1 score: 0.05338946854597596\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[34] train loss: 0.3738616506258647 accuracy: 0.8445413333333334 f1 score: 0.46436414087121103\n",
      "[34] validation loss: 0.6516900062561035 accuracy: 0.823075 f1 score: 0.08601317318868655\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[35] train loss: 0.3794030050436656 accuracy: 0.8450333333333333 f1 score: 0.4239814048460399\n",
      "[35] validation loss: 0.8347617983818054 accuracy: 0.821335 f1 score: 0.06485043573839994\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[36] train loss: 0.3641609847545624 accuracy: 0.8594426666666667 f1 score: 0.48278873515847315\n",
      "[36] validation loss: 0.7147473096847534 accuracy: 0.844525 f1 score: 0.04107688037746323\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[37] train loss: 0.37778990467389423 accuracy: 0.843824 f1 score: 0.42343246994890577\n",
      "[37] validation loss: 0.6972188353538513 accuracy: 0.824605 f1 score: 0.16639338418763813\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[38] train loss: 0.38343092799186707 accuracy: 0.8510893333333334 f1 score: 0.4795541285515237\n",
      "[38] validation loss: 0.7139047980308533 accuracy: 0.84354 f1 score: 0.05192995212991577\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[39] train loss: 0.3933454751968384 accuracy: 0.8313733333333333 f1 score: 0.4973889820606774\n",
      "[39] validation loss: 0.6290419697761536 accuracy: 0.841465 f1 score: 0.06372360844529751\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[40] train loss: 0.3634524742762248 accuracy: 0.8481706666666666 f1 score: 0.5144962139300088\n",
      "[40] validation loss: 0.6158412098884583 accuracy: 0.846155 f1 score: 0.054047406769760505\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[41] train loss: 0.3775845468044281 accuracy: 0.8475693333333333 f1 score: 0.4930401273574656\n",
      "[41] validation loss: 0.5567821264266968 accuracy: 0.849605 f1 score: 0.02546573789081484\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[42] train loss: 0.3571368257204692 accuracy: 0.8615413333333334 f1 score: 0.5100542580797357\n",
      "[42] validation loss: 0.5919339060783386 accuracy: 0.85317 f1 score: 0.024579817976483093\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[43] train loss: 0.38169799248377484 accuracy: 0.8358106666666667 f1 score: 0.4271079516906414\n",
      "[43] validation loss: 0.5626418590545654 accuracy: 0.861495 f1 score: 0.0065272746834989055\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[44] train loss: 0.3770415385564168 accuracy: 0.8350186666666667 f1 score: 0.3766197126332547\n",
      "[44] validation loss: 0.5532962679862976 accuracy: 0.85368 f1 score: 0.026415596513407413\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[45] train loss: 0.3711303770542145 accuracy: 0.8385706666666667 f1 score: 0.40794350934501744\n",
      "[45] validation loss: 0.5516983866691589 accuracy: 0.854815 f1 score: 0.03483463520026591\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[46] train loss: 0.3542465964953105 accuracy: 0.8532746666666666 f1 score: 0.5478213704574217\n",
      "[46] validation loss: 0.6084092855453491 accuracy: 0.781415 f1 score: 0.13488215621475075\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[47] train loss: 0.3469049831231435 accuracy: 0.8604973333333333 f1 score: 0.5242648697067663\n",
      "[47] validation loss: 0.6363793611526489 accuracy: 0.711065 f1 score: 0.21353620860949687\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[48] train loss: 0.36879732211430866 accuracy: 0.8445706666666667 f1 score: 0.4736918145288726\n",
      "[48] validation loss: 0.6389554142951965 accuracy: 0.66949 f1 score: 0.2338664812239221\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[49] train loss: 0.35136570533116657 accuracy: 0.8545506666666667 f1 score: 0.502886880756103\n",
      "[49] validation loss: 0.6561621427536011 accuracy: 0.67246 f1 score: 0.2567564501123238\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[50] train loss: 0.33945443232854206 accuracy: 0.85292 f1 score: 0.5220164484231873\n",
      "[50] validation loss: 0.693962574005127 accuracy: 0.669785 f1 score: 0.2567997929396937\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[51] train loss: 0.356814165910085 accuracy: 0.853128 f1 score: 0.5287287475720679\n",
      "[51] validation loss: 0.6721258759498596 accuracy: 0.818355 f1 score: 0.09464948787599373\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[52] train loss: 0.3450031777222951 accuracy: 0.8533106666666667 f1 score: 0.4722164921252476\n",
      "[52] validation loss: 0.6830279231071472 accuracy: 0.812845 f1 score: 0.03813439547732237\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[53] train loss: 0.3380477825800578 accuracy: 0.857116 f1 score: 0.4899016103159228\n",
      "[53] validation loss: 0.7088789343833923 accuracy: 0.79846 f1 score: 0.061557086980815794\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[54] train loss: 0.34451120098431903 accuracy: 0.8595733333333333 f1 score: 0.49701994345533745\n",
      "[54] validation loss: 0.6629841327667236 accuracy: 0.77894 f1 score: 0.07772539530226541\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[55] train loss: 0.33878421783447266 accuracy: 0.865328 f1 score: 0.5563228084971799\n",
      "[55] validation loss: 0.6843088865280151 accuracy: 0.76712 f1 score: 0.1741551118834001\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[56] train loss: 0.3559941252072652 accuracy: 0.8484186666666667 f1 score: 0.5005930364344015\n",
      "[56] validation loss: 0.6776296496391296 accuracy: 0.75529 f1 score: 0.1904793410301366\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[57] train loss: 0.34515594442685443 accuracy: 0.8588186666666666 f1 score: 0.5238467834048331\n",
      "[57] validation loss: 0.6375349760055542 accuracy: 0.776095 f1 score: 0.20251812013605686\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[58] train loss: 0.3285939395427704 accuracy: 0.869852 f1 score: 0.5573939973791245\n",
      "[58] validation loss: 0.657954752445221 accuracy: 0.740225 f1 score: 0.16094701312963292\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[59] train loss: 0.3391609489917755 accuracy: 0.8664866666666666 f1 score: 0.5419573222331496\n",
      "[59] validation loss: 0.6328725218772888 accuracy: 0.727195 f1 score: 0.15187079324120561\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[60] train loss: 0.34563018878300983 accuracy: 0.8571853333333334 f1 score: 0.5278312886545675\n",
      "[60] validation loss: 0.5926136374473572 accuracy: 0.731505 f1 score: 0.18572490029872474\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[61] train loss: 0.3379171093304952 accuracy: 0.8535546666666667 f1 score: 0.49140094649786537\n",
      "[61] validation loss: 0.5976551175117493 accuracy: 0.730975 f1 score: 0.12539215526910386\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[62] train loss: 0.3349112272262573 accuracy: 0.857168 f1 score: 0.48560397979371145\n",
      "[62] validation loss: 0.5758179426193237 accuracy: 0.72949 f1 score: 0.10033923107622722\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[63] train loss: 0.31428398688634235 accuracy: 0.869972 f1 score: 0.5544565311744738\n",
      "[63] validation loss: 0.5938902497291565 accuracy: 0.729785 f1 score: 0.09133249264396806\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[64] train loss: 0.3301507035891215 accuracy: 0.8499 f1 score: 0.49291225794246024\n",
      "[64] validation loss: 0.6117359399795532 accuracy: 0.73961 f1 score: 0.12735011226917795\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[65] train loss: 0.33994124333063763 accuracy: 0.8510213333333333 f1 score: 0.5153673325988705\n",
      "[65] validation loss: 0.5823268890380859 accuracy: 0.715675 f1 score: 0.1271278800251738\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[66] train loss: 0.3181052307287852 accuracy: 0.864636 f1 score: 0.5331352865164146\n",
      "[66] validation loss: 0.6272315382957458 accuracy: 0.754045 f1 score: 0.11861461002311373\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[67] train loss: 0.31143227219581604 accuracy: 0.8597413333333334 f1 score: 0.5333422056605447\n",
      "[67] validation loss: 0.6807361841201782 accuracy: 0.726625 f1 score: 0.15438390274834898\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[68] train loss: 0.3231400748093923 accuracy: 0.8591746666666666 f1 score: 0.5584951405580522\n",
      "[68] validation loss: 0.6950374841690063 accuracy: 0.724255 f1 score: 0.17858472720773322\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[69] train loss: 0.3173642158508301 accuracy: 0.8667946666666667 f1 score: 0.5881979538503392\n",
      "[69] validation loss: 0.6682458519935608 accuracy: 0.728975 f1 score: 0.14869725001177894\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[70] train loss: 0.32955872019131977 accuracy: 0.8566266666666666 f1 score: 0.513685372119107\n",
      "[70] validation loss: 0.6575668454170227 accuracy: 0.73155 f1 score: 0.09722222222222222\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[71] train loss: 0.32197104891141254 accuracy: 0.8578533333333334 f1 score: 0.5269556728934641\n",
      "[71] validation loss: 0.6547772884368896 accuracy: 0.76194 f1 score: 0.08494772447724477\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[72] train loss: 0.3710586130619049 accuracy: 0.8117466666666666 f1 score: 0.4480712398167404\n",
      "[72] validation loss: 0.6484236121177673 accuracy: 0.699155 f1 score: 0.15886374121035046\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[73] train loss: 0.3286760151386261 accuracy: 0.8641386666666667 f1 score: 0.5345726944685516\n",
      "[73] validation loss: 0.6313672065734863 accuracy: 0.70968 f1 score: 0.21121556267999783\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[74] train loss: 0.3457442820072174 accuracy: 0.861064 f1 score: 0.5240005116211081\n",
      "[74] validation loss: 0.5950924158096313 accuracy: 0.72017 f1 score: 0.19061117056662716\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[75] train loss: 0.3352198302745819 accuracy: 0.85778 f1 score: 0.4411260786871846\n",
      "[75] validation loss: 0.617953896522522 accuracy: 0.72338 f1 score: 0.1668323243275805\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[76] train loss: 0.33391668399175006 accuracy: 0.855544 f1 score: 0.4981099560842737\n",
      "[76] validation loss: 0.6525214910507202 accuracy: 0.706515 f1 score: 0.18800060868482577\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[77] train loss: 0.32648371656735736 accuracy: 0.86224 f1 score: 0.5345862087605182\n",
      "[77] validation loss: 0.6525700092315674 accuracy: 0.69538 f1 score: 0.19777730959654483\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[78] train loss: 0.3263695438702901 accuracy: 0.8608093333333333 f1 score: 0.5264528303598565\n",
      "[78] validation loss: 0.6298018097877502 accuracy: 0.695525 f1 score: 0.1561932739340696\n",
      "\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([10, 3, 25000])\n",
      "torch.Size([8, 3, 25000])\n",
      "[79] train loss: 0.30693859855333966 accuracy: 0.8759053333333333 f1 score: 0.5621074323783893\n",
      "[79] validation loss: 0.6085590720176697 accuracy: 0.731145 f1 score: 0.10002175841464843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "loss_func = CustomLoss()\n",
    "classifier = PointNetDenseCls().to(device)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "num_batch = len(training_data)\n",
    "\n",
    "for epoch in range(80):\n",
    "    # scheduler.step()\n",
    "    classifier.train()\n",
    "    train_loss, train_f1, train_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    for i, data in enumerate(train_dataloader, 1):\n",
    "        points, target = data\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred, _, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "        # print(pred.size(), target.size())\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "        labels = np.append(labels, target.cpu())\n",
    "\n",
    "    train_f1 = f1_score(predictions, labels)\n",
    "    train_acc = sum(predictions == labels)/float(len(labels))\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    classifier.eval()\n",
    "    valid_loss, valid_f1, valid_acc = 0.0, 0.0, 0.0\n",
    "    predictions, labels = np.array([]), np.array([])\n",
    "    for i, data in enumerate(validation_dataloader):\n",
    "        points, target = data\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        pred, _, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "        predictions = np.append(predictions, pred.max(1)[1].cpu())\n",
    "        labels = np.append(labels, target.cpu())\n",
    "\n",
    "    valid_f1 = f1_score(predictions, labels)\n",
    "    valid_acc = sum(predictions == labels)/float(len(labels))\n",
    "    valid_loss /= len(validation_dataloader)\n",
    "\n",
    "    writer.add_scalars('losses', {'training':train_loss, 'validation':valid_loss}, global_step=epoch)\n",
    "    writer.add_scalars('f1 scores', {'training':train_f1, 'validation':valid_f1}, global_step=epoch)\n",
    "\n",
    "    print(f'[{epoch}] train loss: {train_loss} accuracy: {train_acc} f1 score: {train_f1}')\n",
    "    print(f'[{epoch}] validation loss: {valid_loss} accuracy: {valid_acc} f1 score: {valid_f1}')\n",
    "    print()\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825faa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 25000])\n",
      "F1 score:  0.6544759713176224\n",
      "torch.Size([10, 3, 25000])\n",
      "F1 score:  0.558924848825347\n",
      "torch.Size([10, 3, 25000])\n",
      "F1 score:  0.2633047210300429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs = None\n",
    "points = None\n",
    "x = y = None\n",
    "def test_PointNet(pointnet, test_dataloader, device):\n",
    "    global outputs, points, x, y\n",
    "    pointnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (points, labels) in enumerate(test_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            outputs, _, _ = pointnet(points)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            x = labels.view(-1).to('cpu').numpy()\n",
    "            y = predicted.view(-1).to('cpu').numpy()\n",
    "            f1 = f1_score(x, y)\n",
    "            print('F1 score: ', f1)\n",
    "    \n",
    "test_PointNet(classifier, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20bd5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45569\n",
      "16694\n",
      "tensor([[[-1.1129e-01, -2.2508e+00],\n",
      "         [-1.1381e-01, -2.2296e+00],\n",
      "         [-1.2146e-01, -2.1682e+00],\n",
      "         ...,\n",
      "         [-8.0524e-03, -4.8258e+00],\n",
      "         [-2.2432e-01, -1.6047e+00],\n",
      "         [-1.5096e+00, -2.4975e-01]],\n",
      "\n",
      "        [[-4.2806e-02, -3.1724e+00],\n",
      "         [-1.8053e-02, -4.0234e+00],\n",
      "         [-1.3528e-02, -4.3098e+00],\n",
      "         ...,\n",
      "         [-1.7949e-02, -4.0292e+00],\n",
      "         [-1.8144e-02, -4.0185e+00],\n",
      "         [-1.8349e-02, -4.0073e+00]],\n",
      "\n",
      "        [[-3.1332e-01, -1.3131e+00],\n",
      "         [-3.0351e-01, -1.3403e+00],\n",
      "         [-2.9631e-01, -1.3608e+00],\n",
      "         ...,\n",
      "         [-3.9249e-03, -5.5424e+00],\n",
      "         [-4.0114e-03, -5.5206e+00],\n",
      "         [-4.0681e-03, -5.5066e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.7488e-01, -9.7275e-01],\n",
      "         [-4.7584e-01, -9.7118e-01],\n",
      "         [-4.7705e-01, -9.6920e-01],\n",
      "         ...,\n",
      "         [-1.3204e-02, -4.3338e+00],\n",
      "         [-1.3236e-02, -4.3314e+00],\n",
      "         [-1.3118e-02, -4.3403e+00]],\n",
      "\n",
      "        [[-1.4316e-02, -4.2535e+00],\n",
      "         [-2.4425e-02, -3.7243e+00],\n",
      "         [-2.1107e-01, -1.6592e+00],\n",
      "         ...,\n",
      "         [-2.7383e-02, -3.6115e+00],\n",
      "         [-2.7281e-02, -3.6152e+00],\n",
      "         [-2.8457e-02, -3.5736e+00]],\n",
      "\n",
      "        [[-3.1534e-03, -5.7609e+00],\n",
      "         [-3.1853e-03, -5.7508e+00],\n",
      "         [-3.1523e-03, -5.7612e+00],\n",
      "         ...,\n",
      "         [-7.0051e-03, -4.9646e+00],\n",
      "         [-6.9243e-03, -4.9762e+00],\n",
      "         [-7.3121e-03, -4.9219e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(sum(x))\n",
    "print(sum(y))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbbe45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels has 204431 zeroes and 45569 ones\n",
      "Predictions has 233306 zeroes and 16694 ones\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels has {sum(x == 0)} zeroes and {sum(x == 1)} ones\")\n",
    "print(f\"Predictions has {sum(y == 0)} zeroes and {sum(y == 1)} ones\")\n",
    "\n",
    "\n",
    "# writer.add_graph(model, points)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c64757",
   "metadata": {},
   "source": [
    "73.4029268292683% on roofs (5)\n",
    "86.77414634146342% on trees (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

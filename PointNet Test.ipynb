{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import laspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669251ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, pts_file):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        # do i need to min max intensity, return number, number of returns, etc.? probably not\n",
    "        for i in range(3):\n",
    "            dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "            points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "        self.data = points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 5000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 5000 points\n",
    "        xyzirn = self.data[idx * 5000: (idx + 1) * 5000, :6]  # x, y, z, intensity, return number, number of returns\n",
    "        label = self.data[idx * 5000: (idx + 1) * 5000, 6] == 8\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float()\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return xyzirn, label\n",
    "\n",
    "training_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_Traininig.pts\")\n",
    "testing_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\")\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63435af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) # can/should i use shuffle, try lowering it?\n",
    "test_dataloader = DataLoader(testing_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2f1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 6, 5000])\n",
      "Labels batch shape: torch.Size([64, 5000])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4086ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b033a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.mlp1 = nn.Sequential(torch.nn.Conv1d(k, 64, 1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(torch.nn.Conv1d(64, 128, 1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp3 = nn.Sequential(torch.nn.Conv1d(128, 1024, 1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Linear(512, 256), nn.BatchNorm1d(256), nn.GELU())\n",
    "        self.fc = nn.Linear(256, k*k)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.mlp3(x)\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = self.mlp4(x)\n",
    "        x = self.mlp5(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        iden = torch.eye(self.k, requires_grad=True).repeat(batchsize,1,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x.view(-1, self.k, self.k) + iden\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "363013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class PoinNet(nn.Module):\n",
    "    def __init__(self, input_dim=6, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Should GELU be after LayerNorm?\n",
    "        self.stn1 = STNkd(k=input_dim)\n",
    "        self.mlp1 = nn.Sequential(nn.Conv1d(input_dim, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp2 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        \n",
    "        self.stn2 = STNkd(k=64)\n",
    "        # can i call mlp2 again?\n",
    "        self.mlp3 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=1), nn.BatchNorm1d(64), nn.GELU())\n",
    "        self.mlp4 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=1), nn.BatchNorm1d(128), nn.GELU())\n",
    "        self.mlp5 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1), nn.BatchNorm1d(1024), nn.GELU())\n",
    "        \n",
    "        self.mlp6 = nn.Sequential(nn.Linear(1088, 512), nn.LayerNorm(512), nn.GELU())\n",
    "        self.mlp7 = nn.Sequential(nn.Linear(512, 256), nn.LayerNorm(256), nn.GELU())\n",
    "        self.mlp8 = nn.Sequential(nn.Linear(256, 128), nn.LayerNorm(128), nn.GELU())\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "\n",
    "        trans6x6 = self.stn1(x) \n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans6x6)\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "        print(1, x.size())\n",
    "        x = self.mlp2(x)\n",
    "        print(2, x.size())\n",
    "        \n",
    "        \n",
    "        trans64x64 = self.stn2(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans64x64)\n",
    "        local_features = x.transpose(2, 1)\n",
    "\n",
    "        x = self.mlp3(local_features)\n",
    "        print(3, x.size())\n",
    "        x = self.mlp4(x)\n",
    "        print(4, x.size())\n",
    "        x = self.mlp5(x)\n",
    "        print(5, x.size())\n",
    "        x = torch.max(x, 2)[0]\n",
    "        print(6, x.size())\n",
    "        \n",
    "        # FOR CLASSIFICATION\n",
    "        # x = self.mlp6(x)\n",
    "        # print(6, x.size())\n",
    "        # x = self.mlp7(x)\n",
    "        # print(7, x.size())\n",
    "        # x = self.fc(x)\n",
    "        # print(8, x.size())\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "\n",
    "        global_features = x.unsqueeze(2).repeat(1, 1, n_pts)\n",
    "        print(7, global_features.size())\n",
    "        x = torch.cat([local_features, global_features], 1)\n",
    "        print(8, x.size())\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.mlp6(x)\n",
    "        print(9, x.size())\n",
    "        x = self.mlp7(x)\n",
    "        print(10, x.size())\n",
    "        x = self.mlp8(x)\n",
    "        print(11, x.size())\n",
    "        x = self.fc(x)\n",
    "        print(12, x.size())\n",
    "        return x, trans64x64\n",
    "\n",
    "model = PoinNet(input_dim=6, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90bb5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, trans):\n",
    "        d = trans.size(1)\n",
    "        I = torch.eye(d).unsqueeze(0).to(device)\n",
    "        loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "        print(loss.size())\n",
    "        loss = torch.mean(loss)\n",
    "        return self.cross_entropy_loss(inputs, targets) + loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99462857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(112.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 0\tLoss: 112.76699829101562\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(75.9059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 1\tLoss: 75.90592193603516\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(22.5743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 2\tLoss: 22.574268341064453\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(28.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 0\tLoss: 28.887664794921875\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(10.3399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 1\tLoss: 10.339916229248047\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(8.2620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 2\tLoss: 8.261983871459961\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(11.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 0\tLoss: 11.751212120056152\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(9.2787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 1\tLoss: 9.27867317199707\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(7.8491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 2\tLoss: 7.849076271057129\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(7.6228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 0\tLoss: 7.622793674468994\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(7.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 1\tLoss: 7.460920333862305\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(6.1039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 2\tLoss: 6.103912830352783\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(6.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 0\tLoss: 6.391271114349365\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(5.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 1\tLoss: 5.923327445983887\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(5.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 2\tLoss: 5.057680606842041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_PointNet(num_epochs, pointnet, train_dataloader, device, num_classes):\n",
    "    pointnet.train()\n",
    "    loss_func = CustomLoss()\n",
    "    optimizer = optim.Adam(pointnet.parameters(), lr = 0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (points, labels) in enumerate(train_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            print(labels.size())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out, trans = pointnet(points)\n",
    "            out = out.view(-1, num_classes)\n",
    "            labels = labels.view(-1)\n",
    "            print(out.size())\n",
    "            print(labels.size())\n",
    "            loss = loss_func(out, labels, trans)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            print(f\"Epoch: {epoch+1}\\tBatch ID: {batch_idx}\\tLoss: {loss.item()}\")\n",
    "            print()\n",
    "\n",
    "train_PointNet(5, model, train_dataloader, device, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825faa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([64, 5000, 2])\n",
      "torch.Size([64, 5000])\n",
      "torch.Size([10, 6])\n",
      "torch.Size([64, 5000])\n",
      "[[0.004283   0.4452669  0.0191022  ... 1.         1.         1.        ]\n",
      " [0.004283   0.44536626 0.01846546 ... 1.         1.         1.        ]\n",
      " [0.004283   0.44539109 0.01942057 ... 1.         1.         1.        ]\n",
      " ...\n",
      " [0.00430977 0.44561464 0.01942057 ... 1.         1.         1.        ]\n",
      " [0.00430977 0.44566432 0.0191022  ... 1.         1.         1.        ]\n",
      " [0.00430977 0.445714   0.01846546 ... 1.         1.         1.        ]]\n",
      "(64, 5000)\n",
      "(64, 5000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_26516\\1715964154.py\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# print(f'Accuracy of the model on test images: {100 * correct / total}% on {total} values') # use F1 from scikit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtest_PointNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_26516\\1715964154.py\u001b[0m in \u001b[0;36mtest_PointNet\u001b[1;34m(pointnet, test_dataloader, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\and13375\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\point-segmentation\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \"\"\"\n\u001b[1;32m-> 1123\u001b[1;33m     return fbeta_score(\n\u001b[0m\u001b[0;32m   1124\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\and13375\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\point-segmentation\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \"\"\"\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\and13375\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\point-segmentation\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\and13375\\AppData\\Local\\Programs\\ArcGIS\\Pro\\bin\\Python\\envs\\point-segmentation\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"samples\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1366\u001b[0m                 \u001b[1;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m                 \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_PointNet(pointnet, test_dataloader, device):\n",
    "    pointnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No need to track gradients in testing phase\n",
    "        for idx, (points, labels) in enumerate(test_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            outputs, _ = pointnet(points)\n",
    "            print(outputs.size())\n",
    "            _, predicted = torch.max(outputs.data, 2) # returns max values, index of max values\n",
    "            print(predicted.size())\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            print(points.transpose(1,2)[0][:10].size())\n",
    "            print(labels.size())\n",
    "            print(np.hstack([points.transpose(1,2)[0][:10].to('cpu'), labels[:10].to('cpu'), (predicted[:10]==labels[:10]).to('cpu')])[:20])\n",
    "            x = labels.to('cpu').numpy()\n",
    "            y = predicted.to('cpu').numpy()\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            f1 = f1_score(x, y)\n",
    "            print('F1 score: ', f1)\n",
    "            break\n",
    "    # print(f'Accuracy of the model on test images: {100 * correct / total}% on {total} values') # use F1 from scikit\n",
    "    \n",
    "test_PointNet(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4f07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(112.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 0\tLoss: 112.76699829101562\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(75.9059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 1\tLoss: 75.90592193603516\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(22.5743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1\tBatch ID: 2\tLoss: 22.574268341064453\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(28.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 0\tLoss: 28.887664794921875\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(10.3399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 1\tLoss: 10.339916229248047\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(8.2620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 2\tBatch ID: 2\tLoss: 8.261983871459961\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(11.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 0\tLoss: 11.751212120056152\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(9.2787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 1\tLoss: 9.27867317199707\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(7.8491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 3\tBatch ID: 2\tLoss: 7.849076271057129\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(7.6228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 0\tLoss: 7.622793674468994\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(7.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 1\tLoss: 7.460920333862305\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(6.1039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 4\tBatch ID: 2\tLoss: 6.103912830352783\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(6.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 0\tLoss: 6.391271114349365\n",
      "\n",
      "torch.Size([64, 5000])\n",
      "1 torch.Size([64, 64, 5000])\n",
      "2 torch.Size([64, 64, 5000])\n",
      "3 torch.Size([64, 64, 5000])\n",
      "4 torch.Size([64, 128, 5000])\n",
      "5 torch.Size([64, 1024, 5000])\n",
      "6 torch.Size([64, 1024])\n",
      "7 torch.Size([64, 1024, 5000])\n",
      "8 torch.Size([64, 1088, 5000])\n",
      "9 torch.Size([64, 5000, 512])\n",
      "10 torch.Size([64, 5000, 256])\n",
      "11 torch.Size([64, 5000, 128])\n",
      "12 torch.Size([64, 5000, 2])\n",
      "torch.Size([320000, 2])\n",
      "torch.Size([320000])\n",
      "torch.Size([64])\n",
      "tensor(5.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 1\tLoss: 5.923327445983887\n",
      "\n",
      "torch.Size([22, 5000])\n",
      "1 torch.Size([22, 64, 5000])\n",
      "2 torch.Size([22, 64, 5000])\n",
      "3 torch.Size([22, 64, 5000])\n",
      "4 torch.Size([22, 128, 5000])\n",
      "5 torch.Size([22, 1024, 5000])\n",
      "6 torch.Size([22, 1024])\n",
      "7 torch.Size([22, 1024, 5000])\n",
      "8 torch.Size([22, 1088, 5000])\n",
      "9 torch.Size([22, 5000, 512])\n",
      "10 torch.Size([22, 5000, 256])\n",
      "11 torch.Size([22, 5000, 128])\n",
      "12 torch.Size([22, 5000, 2])\n",
      "torch.Size([110000, 2])\n",
      "torch.Size([110000])\n",
      "torch.Size([22])\n",
      "tensor(5.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 5\tBatch ID: 2\tLoss: 5.057680606842041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_PointNet(num_epochs, pointnet, train_dataloader, device, num_classes):\n",
    "    pointnet.train()\n",
    "    loss_func = CustomLoss()\n",
    "    optimizer = optim.Adam(pointnet.parameters(), lr = 0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (points, labels) in enumerate(train_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            print(labels.size())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out, trans = pointnet(points)\n",
    "            out = out.view(-1, num_classes)\n",
    "            labels = labels.view(-1)\n",
    "            print(out.size())\n",
    "            print(labels.size())\n",
    "            loss = loss_func(out, labels, trans)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            print(f\"Epoch: {epoch+1}\\tBatch ID: {batch_idx}\\tLoss: {loss.item()}\")\n",
    "            print()\n",
    "\n",
    "train_PointNet(5, model, train_dataloader, device, num_classes=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c64757",
   "metadata": {},
   "source": [
    "73.4029268292683% on roofs (5)\n",
    "86.77414634146342% on trees (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "# from torchvision.transforms import ToTensorfrom \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669251ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753876, 4)\n",
      "(411722, 4)\n"
     ]
    }
   ],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, pts_file):\n",
    "        points = np.loadtxt(pts_file, delimiter=' ')\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "        points = np.delete(points, -2, 1)\n",
    "\n",
    "        print(points.shape)\n",
    "        # do i need to min max intensity, return number, number of returns, etc.? probably not\n",
    "        for i in range(3):\n",
    "            dim_min, dim_max = min(points[:,i]), max(points[:,i])\n",
    "            points[:,i] = (points[:,i] - dim_min) / (dim_max - dim_min)\n",
    "        self.data = points\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) // 25000\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Return batches of 2500 points\n",
    "        xyzirn = self.data[idx * 25000: (idx + 1) * 25000, :3]  # x, y, z, ***intensity, return number, number of returns***\n",
    "        label = self.data[idx * 25000: (idx + 1) * 25000, 3] == 8\n",
    "\n",
    "        xyzirn = torch.from_numpy(xyzirn.T).float()\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return xyzirn, label\n",
    "\n",
    "training_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_Traininig.pts\")\n",
    "testing_data = PointCloudDataset(r\"C:\\Users\\and13375\\Documents\\3D Point Segmentation\\Test\\Vaihingen\\3DLabeling\\Vaihingen3D_EVAL_WITH_REF.pts\")\n",
    "train_dataloader = DataLoader(training_data, batch_size=10, shuffle=False) # can/should i use shuffle, try lowering it?\n",
    "test_dataloader = DataLoader(testing_data, batch_size=10, shuffle=False)\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2f1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 3, 25000])\n",
      "Labels batch shape: torch.Size([10, 25000])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d56a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Counter({0: 16517, 1: 8483}) 25000\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def plot_batch(entire_view = True):\n",
    "    # Assuming pc is your point cloud data, in shape (N, 3)\n",
    "    pc_num = 0\n",
    "\n",
    "    if entire_view:\n",
    "        pc = training_data.data[:, :3]\n",
    "        labels = training_data.data[:, 3] == 8\n",
    "    else:\n",
    "        pc = training_data[pc_num][0].T.view(-1,3).numpy()\n",
    "        labels = training_data[pc_num][1].numpy()\n",
    "\n",
    "    print(Counter(labels), len(labels))\n",
    "\n",
    "    # Define colors for each label\n",
    "    color_map = {0: [0.5, 0.5, 0.5],  # Gray color for label 0\n",
    "                1: [1.0, 0.0, 0.0]}  # Red color for label 1\n",
    "\n",
    "    # Map each label to a color\n",
    "    colors = np.array([color_map[label] for label in labels])\n",
    "\n",
    "    # Create point cloud\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pc)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n",
    "# plot_batch(entire_view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4086ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "# device = 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = True):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=True):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "    \n",
    "# model = PointNetDenseCls(k=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20254b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if name == 'mlp8.1':\n",
    "#         print(name)\n",
    "#     # print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size(1)\n",
    "    I = torch.eye(d).unsqueeze(0).to(device)\n",
    "    loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e075a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, trans):\n",
    "        d = trans.size(1)\n",
    "        I = torch.eye(d).unsqueeze(0).to(device)\n",
    "        loss = torch.linalg.norm(I - torch.bmm(trans, trans.transpose(2,1)), dim=(1,2))\n",
    "        loss = torch.mean(loss)\n",
    "        return self.cross_entropy_loss(inputs, targets) + loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cad6a3",
   "metadata": {},
   "source": [
    "## Online Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294c68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[1: 1/3] train loss: 0.973839 accuracy: 0.337036 f1 score: 0.432435\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[1: 2/3] train loss: 0.972608 accuracy: 0.294128 f1 score: 0.186753\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[1: 3/3] train loss: 0.945896 accuracy: 0.436900 f1 score: 0.305908\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[2: 1/3] train loss: 0.872048 accuracy: 0.511428 f1 score: 0.384853\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[2: 2/3] train loss: 0.900995 accuracy: 0.393016 f1 score: 0.141290\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[2: 3/3] train loss: 0.786034 accuracy: 0.734464 f1 score: 0.212956\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[3: 1/3] train loss: 0.806216 accuracy: 0.616108 f1 score: 0.305233\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[3: 2/3] train loss: 0.684743 accuracy: 0.828776 f1 score: 0.332991\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[3: 3/3] train loss: 0.686987 accuracy: 0.800212 f1 score: 0.261063\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[4: 1/3] train loss: 0.736948 accuracy: 0.725104 f1 score: 0.300846\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[4: 2/3] train loss: 0.587908 accuracy: 0.892968 f1 score: 0.001791\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[4: 3/3] train loss: 0.618948 accuracy: 0.835488 f1 score: 0.000000\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[5: 1/3] train loss: 0.710151 accuracy: 0.730608 f1 score: 0.000000\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[5: 2/3] train loss: 0.519526 accuracy: 0.892968 f1 score: 0.000000\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[5: 3/3] train loss: 0.581437 accuracy: 0.843372 f1 score: 0.178082\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[6: 1/3] train loss: 0.687640 accuracy: 0.730216 f1 score: 0.024952\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[6: 2/3] train loss: 0.471694 accuracy: 0.892976 f1 score: 0.000149\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[6: 3/3] train loss: 0.543452 accuracy: 0.828868 f1 score: 0.015328\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[7: 1/3] train loss: 0.660292 accuracy: 0.729664 f1 score: 0.020862\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[7: 2/3] train loss: 0.429013 accuracy: 0.894400 f1 score: 0.078148\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[7: 3/3] train loss: 0.509311 accuracy: 0.834872 f1 score: 0.049546\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[8: 1/3] train loss: 0.630640 accuracy: 0.729528 f1 score: 0.019887\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[8: 2/3] train loss: 0.401560 accuracy: 0.895244 f1 score: 0.043883\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[8: 3/3] train loss: 0.484899 accuracy: 0.829080 f1 score: 0.017746\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[9: 1/3] train loss: 0.601186 accuracy: 0.738624 f1 score: 0.105342\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[9: 2/3] train loss: 0.382177 accuracy: 0.890760 f1 score: 0.249148\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[9: 3/3] train loss: 0.472393 accuracy: 0.829064 f1 score: 0.119286\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[10: 1/3] train loss: 0.587781 accuracy: 0.730972 f1 score: 0.053611\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[10: 2/3] train loss: 0.377451 accuracy: 0.889868 f1 score: 0.139513\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[10: 3/3] train loss: 0.463136 accuracy: 0.831384 f1 score: 0.164804\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[11: 1/3] train loss: 0.589137 accuracy: 0.750940 f1 score: 0.192088\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[11: 2/3] train loss: 0.363470 accuracy: 0.891056 f1 score: 0.185575\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[11: 3/3] train loss: 0.441861 accuracy: 0.837324 f1 score: 0.083392\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[12: 1/3] train loss: 0.581510 accuracy: 0.740064 f1 score: 0.139194\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[12: 2/3] train loss: 0.350538 accuracy: 0.896676 f1 score: 0.163748\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[12: 3/3] train loss: 0.425930 accuracy: 0.846740 f1 score: 0.210016\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[13: 1/3] train loss: 0.569895 accuracy: 0.754932 f1 score: 0.211016\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[13: 2/3] train loss: 0.338424 accuracy: 0.889884 f1 score: 0.243522\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[13: 3/3] train loss: 0.415390 accuracy: 0.838104 f1 score: 0.267969\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[14: 1/3] train loss: 0.547435 accuracy: 0.741328 f1 score: 0.220041\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[14: 2/3] train loss: 0.334528 accuracy: 0.889172 f1 score: 0.252999\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[14: 3/3] train loss: 0.409743 accuracy: 0.836136 f1 score: 0.248634\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[15: 1/3] train loss: 0.523483 accuracy: 0.753352 f1 score: 0.246186\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[15: 2/3] train loss: 0.330967 accuracy: 0.890800 f1 score: 0.267035\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[15: 3/3] train loss: 0.401993 accuracy: 0.849732 f1 score: 0.297301\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[16: 1/3] train loss: 0.502780 accuracy: 0.763896 f1 score: 0.354822\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[16: 2/3] train loss: 0.326160 accuracy: 0.885904 f1 score: 0.295634\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[16: 3/3] train loss: 0.414668 accuracy: 0.846564 f1 score: 0.307562\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[17: 1/3] train loss: 0.497362 accuracy: 0.763032 f1 score: 0.353394\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[17: 2/3] train loss: 0.344305 accuracy: 0.894424 f1 score: 0.162308\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[17: 3/3] train loss: 0.390788 accuracy: 0.844276 f1 score: 0.222018\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[18: 1/3] train loss: 0.530144 accuracy: 0.772736 f1 score: 0.409213\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[18: 2/3] train loss: 0.327085 accuracy: 0.886852 f1 score: 0.327125\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[18: 3/3] train loss: 0.384041 accuracy: 0.850208 f1 score: 0.224583\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[19: 1/3] train loss: 0.506629 accuracy: 0.765100 f1 score: 0.438903\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[19: 2/3] train loss: 0.367650 accuracy: 0.885068 f1 score: 0.107865\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[19: 3/3] train loss: 0.387401 accuracy: 0.848504 f1 score: 0.230954\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[20: 1/3] train loss: 0.542099 accuracy: 0.740800 f1 score: 0.305392\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[20: 2/3] train loss: 0.315537 accuracy: 0.890596 f1 score: 0.225952\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[20: 3/3] train loss: 0.387997 accuracy: 0.850468 f1 score: 0.376981\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[21: 1/3] train loss: 0.521256 accuracy: 0.745868 f1 score: 0.346362\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[21: 2/3] train loss: 0.329001 accuracy: 0.880000 f1 score: 0.305620\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[21: 3/3] train loss: 0.382828 accuracy: 0.832548 f1 score: 0.347105\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[22: 1/3] train loss: 0.488128 accuracy: 0.758372 f1 score: 0.335230\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[22: 2/3] train loss: 0.335754 accuracy: 0.890964 f1 score: 0.272181\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[22: 3/3] train loss: 0.366644 accuracy: 0.851024 f1 score: 0.326291\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[23: 1/3] train loss: 0.472853 accuracy: 0.787216 f1 score: 0.510787\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[23: 2/3] train loss: 0.312371 accuracy: 0.896748 f1 score: 0.193722\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[23: 3/3] train loss: 0.365395 accuracy: 0.853116 f1 score: 0.283730\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[24: 1/3] train loss: 0.486311 accuracy: 0.772352 f1 score: 0.434825\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[24: 2/3] train loss: 0.314591 accuracy: 0.895200 f1 score: 0.149516\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[24: 3/3] train loss: 0.352926 accuracy: 0.849892 f1 score: 0.243849\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[25: 1/3] train loss: 0.453523 accuracy: 0.788344 f1 score: 0.525000\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[25: 2/3] train loss: 0.307221 accuracy: 0.890160 f1 score: 0.280210\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[25: 3/3] train loss: 0.344129 accuracy: 0.860752 f1 score: 0.380128\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[26: 1/3] train loss: 0.454635 accuracy: 0.776460 f1 score: 0.410775\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[26: 2/3] train loss: 0.312278 accuracy: 0.893220 f1 score: 0.262345\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[26: 3/3] train loss: 0.343240 accuracy: 0.853252 f1 score: 0.417028\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[27: 1/3] train loss: 0.458847 accuracy: 0.780120 f1 score: 0.526080\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[27: 2/3] train loss: 0.303533 accuracy: 0.893104 f1 score: 0.243203\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[27: 3/3] train loss: 0.395231 accuracy: 0.845148 f1 score: 0.197475\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[28: 1/3] train loss: 0.458990 accuracy: 0.758936 f1 score: 0.406363\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[28: 2/3] train loss: 0.306468 accuracy: 0.890872 f1 score: 0.291340\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[28: 3/3] train loss: 0.352313 accuracy: 0.843852 f1 score: 0.393600\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[29: 1/3] train loss: 0.453660 accuracy: 0.782900 f1 score: 0.412144\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[29: 2/3] train loss: 0.307063 accuracy: 0.890176 f1 score: 0.241715\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[29: 3/3] train loss: 0.356865 accuracy: 0.849620 f1 score: 0.251826\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[30: 1/3] train loss: 0.448060 accuracy: 0.766104 f1 score: 0.379138\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[30: 2/3] train loss: 0.320684 accuracy: 0.884588 f1 score: 0.146184\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[30: 3/3] train loss: 0.358964 accuracy: 0.845144 f1 score: 0.413868\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[31: 1/3] train loss: 0.420123 accuracy: 0.784464 f1 score: 0.476560\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[31: 2/3] train loss: 0.327682 accuracy: 0.886596 f1 score: 0.272174\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[31: 3/3] train loss: 0.347725 accuracy: 0.849872 f1 score: 0.395464\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[32: 1/3] train loss: 0.414847 accuracy: 0.809728 f1 score: 0.573259\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[32: 2/3] train loss: 0.310623 accuracy: 0.888428 f1 score: 0.366831\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[32: 3/3] train loss: 0.336734 accuracy: 0.850244 f1 score: 0.378905\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[33: 1/3] train loss: 0.401568 accuracy: 0.789936 f1 score: 0.488955\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[33: 2/3] train loss: 0.311091 accuracy: 0.885664 f1 score: 0.334234\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[33: 3/3] train loss: 0.327233 accuracy: 0.863036 f1 score: 0.441137\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[34: 1/3] train loss: 0.378482 accuracy: 0.834164 f1 score: 0.646203\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[34: 2/3] train loss: 0.297552 accuracy: 0.893404 f1 score: 0.023453\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[34: 3/3] train loss: 0.325067 accuracy: 0.862164 f1 score: 0.404720\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[35: 1/3] train loss: 0.381635 accuracy: 0.830644 f1 score: 0.658559\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[35: 2/3] train loss: 0.296385 accuracy: 0.889452 f1 score: 0.228943\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[35: 3/3] train loss: 0.332186 accuracy: 0.863612 f1 score: 0.546359\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[36: 1/3] train loss: 0.435078 accuracy: 0.795364 f1 score: 0.595808\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[36: 2/3] train loss: 0.304817 accuracy: 0.886724 f1 score: 0.370899\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[36: 3/3] train loss: 0.351577 accuracy: 0.846448 f1 score: 0.376697\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[37: 1/3] train loss: 0.422101 accuracy: 0.791328 f1 score: 0.537796\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[37: 2/3] train loss: 0.302818 accuracy: 0.888512 f1 score: 0.317866\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[37: 3/3] train loss: 0.331918 accuracy: 0.857952 f1 score: 0.340710\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[38: 1/3] train loss: 0.500649 accuracy: 0.809768 f1 score: 0.584211\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[38: 2/3] train loss: 0.312186 accuracy: 0.893104 f1 score: 0.103282\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[38: 3/3] train loss: 0.366016 accuracy: 0.856120 f1 score: 0.471247\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[39: 1/3] train loss: 0.484846 accuracy: 0.800328 f1 score: 0.546381\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[39: 2/3] train loss: 0.324638 accuracy: 0.895252 f1 score: 0.092336\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[39: 3/3] train loss: 0.331177 accuracy: 0.861884 f1 score: 0.423681\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[40: 1/3] train loss: 0.435760 accuracy: 0.795616 f1 score: 0.449918\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[40: 2/3] train loss: 0.317653 accuracy: 0.888712 f1 score: 0.357756\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n",
      "[40: 3/3] train loss: 0.334958 accuracy: 0.853180 f1 score: 0.403258\n",
      "torch.Size([250000, 2]) torch.Size([250000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_3028\\3601737158.py\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfeature_transform_regularizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans_feat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_3028\\609629857.py\u001b[0m in \u001b[0;36mfeature_transform_regularizer\u001b[1;34m(trans)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_transform_regularizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "loss_func = CustomLoss()\n",
    "classifier = PointNetDenseCls()\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "classifier.to(device)\n",
    "\n",
    "num_batch = len(training_data)\n",
    "\n",
    "for epoch in range(80):\n",
    "    # scheduler.step()\n",
    "    for i, data in enumerate(train_dataloader, 1):\n",
    "        points, target = data\n",
    "        # points = points.transpose(2, 1)\n",
    "        points, target = points.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        classifier.train()\n",
    "        pred, _, trans_feat = classifier(points)\n",
    "        pred = pred.view(-1, num_classes)\n",
    "        target = target.view(-1, 1).squeeze()\n",
    "        print(pred.size(), target.size())\n",
    "\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        loss += feature_transform_regularizer(trans_feat) * 0.001\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        f1 = f1_score(pred_choice.cpu(), target.cpu())\n",
    "\n",
    "        writer.add_scalar('training loss', loss.item(), global_step=epoch * len(train_dataloader) + i-1)\n",
    "        writer.add_scalar('training f1 score', f1, global_step=epoch * len(train_dataloader) + i-1)\n",
    "\n",
    "        print('[%d: %d/%d] train loss: %f accuracy: %f f1 score: %f' % (epoch+1, i, 3, loss.item(), correct.item()/float(10 * 25000), f1))\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825faa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.290690634750617\n",
      "F1 score:  0.3281325294753863\n",
      "F1 score:  0.41356752918718204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "outputs = None\n",
    "points = None\n",
    "x = y = None\n",
    "def test_PointNet(pointnet, test_dataloader, device):\n",
    "    global outputs, points, x, y\n",
    "    pointnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (points, labels) in enumerate(test_dataloader):\n",
    "            points, labels = points.to(device), labels.to(device)\n",
    "            outputs, _, _ = pointnet(points)\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            x = labels.view(-1).to('cpu').numpy()\n",
    "            y = predicted.view(-1).to('cpu').numpy()\n",
    "            f1 = f1_score(x, y)\n",
    "            print('F1 score: ', f1)\n",
    "    \n",
    "test_PointNet(classifier, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19507\n",
      "72246\n",
      "tensor([[[-9.3352e-01, -4.9950e-01],\n",
      "         [-9.0994e-01, -5.1509e-01],\n",
      "         [-8.8256e-01, -5.3396e-01],\n",
      "         ...,\n",
      "         [-1.5780e+00, -2.3117e-01],\n",
      "         [-1.5762e+00, -2.3163e-01],\n",
      "         [-1.5755e+00, -2.3180e-01]],\n",
      "\n",
      "        [[-6.3463e-01, -7.5531e-01],\n",
      "         [-6.3452e-01, -7.5542e-01],\n",
      "         [-6.3266e-01, -7.5753e-01],\n",
      "         ...,\n",
      "         [-9.1410e-01, -5.1229e-01],\n",
      "         [-9.0881e-01, -5.1584e-01],\n",
      "         [-9.0045e-01, -5.2153e-01]],\n",
      "\n",
      "        [[-2.9890e-02, -3.5251e+00],\n",
      "         [-3.0132e-02, -3.5172e+00],\n",
      "         [-3.0496e-02, -3.5054e+00],\n",
      "         ...,\n",
      "         [-5.1453e-03, -5.2722e+00],\n",
      "         [-5.2948e-03, -5.2437e+00],\n",
      "         [-5.6095e-03, -5.1861e+00]],\n",
      "\n",
      "        [[-2.1207e-02, -3.8640e+00],\n",
      "         [-2.1764e-02, -3.8383e+00],\n",
      "         [-2.1084e-02, -3.8698e+00],\n",
      "         ...,\n",
      "         [-3.4889e-01, -1.2224e+00],\n",
      "         [-3.5079e-01, -1.2178e+00],\n",
      "         [-3.2735e-01, -1.2759e+00]],\n",
      "\n",
      "        [[-3.7121e-01, -1.1709e+00],\n",
      "         [-3.5531e-01, -1.2072e+00],\n",
      "         [-3.4695e-01, -1.2270e+00],\n",
      "         ...,\n",
      "         [-1.9310e-04, -8.5524e+00],\n",
      "         [-1.9536e-04, -8.5405e+00],\n",
      "         [-2.0037e-04, -8.5153e+00]],\n",
      "\n",
      "        [[-2.7299e-05, -1.0509e+01],\n",
      "         [-2.9087e-05, -1.0447e+01],\n",
      "         [-2.9563e-05, -1.0429e+01],\n",
      "         ...,\n",
      "         [-1.0258e+00, -4.4398e-01],\n",
      "         [-1.0300e+00, -4.4161e-01],\n",
      "         [-1.0530e+00, -4.2905e-01]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum(x))\n",
    "print(sum(y))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels has 130493 zeroes and 19507 ones\n",
      "Predictions has 77754 zeroes and 72246 ones\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels has {sum(x == 0)} zeroes and {sum(x == 1)} ones\")\n",
    "print(f\"Predictions has {sum(y == 0)} zeroes and {sum(y == 1)} ones\")\n",
    "\n",
    "\n",
    "# writer.add_graph(model, points)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c64757",
   "metadata": {},
   "source": [
    "73.4029268292683% on roofs (5)\n",
    "86.77414634146342% on trees (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
